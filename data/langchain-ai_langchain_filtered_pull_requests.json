[
    {
        "merged": false,
        "additions": 191,
        "deletions": 32,
        "changed_files": 10,
        "created_at": "2023-10-18T09:46:44Z",
        "closed_at": null,
        "merged_at": null,
        "body": "By default replace input_variables with the correct value\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 299,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2023-10-18T09:01:24Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:**\r\nAs with `document_compressors`, it seems important to provide a pipeline for transformers.\r\nThe algorithm is different of `DocumentCompressorPipeline`. The idea is to have several transformers to apply to the same document, in order to have several embeddings for the same fragment (via a `ParentDocumentRetriever`). You therefore need to retrieve all the transformations, rather than chaining them together as `DocumentCompressorPipeline` does.\r\n\r\n- `DocumentTransformerPipeline` is used when importing data into a vector store, to have multiple embedding for the same fragment. \r\n- `DocumentCompressorPipeline\u0300 is used when reading documents, to filter them.\r\n\r\n\r\nCombined with this [pull-request](https://github.com/langchain-ai/langchain/pull/11968), it's easy to chain transformations while maintaining the link with the original document.\r\n\r\nI propose 3 more transformers, to generate a summary and ask questions about the document.\r\nThe last one is a simple transformer without transformation. A simple copy of input to output.\r\n\r\nI must explain the usage.\r\n\r\n1. You split a big document to fragments\r\n2. For each fragment, you want to generate a summary\r\n3. For each fragment, you want to generate 3 questions, and generate a document one for each question\r\n4. Then, you want to save the original fragment, the summary and the 3 questions in a vectorstore\r\n5. You can use `ParentDocumentRetriever` to maintain the association with the original fragment.\r\n6. When you use the `ParentDocumentRetriever`, all the embedding from the summary, the questions or the orginal fragment can select the same fragment.\r\n\r\nBut, `BaseDocumentTransformer` invoke a list of transformer to apply. If I use it with only the `SummarizeTransformer` and `GenerateQuestionsTransformer`, the result is composed with the summary and questions. But the original fragment are not in the result.\r\n\r\nSo the \u0300`CopyDocumentTransformer` can add the original fragment.\r\n\r\nThen, with `ParentDocumentVectorStore`, you can write:\r\n\r\n```\r\nvs = ParentDocumentVectorStore(\r\n    vectorstore=vs,\r\n    docstore=self.docstore,\r\n    id_key=ID_KEY,\r\n    parent_transformer=RecursiveCharacterTextSplitter(),\r\n    child_transformer=DocumentTransformerPipeline(\r\n        transformers=[\r\n            GenerateQuestions.from_llm(llm),\r\n            SummarizeTransformer.from_llm(llm),\r\n            CopyDocumentTransformer(),\r\n        ]\r\n    ),\r\n)\r\nvs.add_documents(documents) # Split, summarize, ask questions and import\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 38,
        "deletions": 23,
        "changed_files": 6,
        "created_at": "2023-10-18T08:45:44Z",
        "closed_at": null,
        "merged_at": null,
        "body": ".dict() is a Pydantic method that cannot raise exceptions, as it is used eg. in `__eq__`\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-18T08:36:39Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- **Description:** According to the document https://cloud.baidu.com/doc/WENXINWORKSHOP/s/clntwmv7t, add ERNIE-Bot-4 model support for ErnieBotChat.\r\n- **Dependencies:** Before using the ERNIE-Bot-4, you should have the model's access authority.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 116,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-18T08:24:58Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:**\r\nThe current implementation of `ParentDocumentRetriever` need two splitter: `child_splitter` and `parent_splitter`.\r\n\r\nBut a splitter is a kind of `BaseDocumentTransformer`.\r\n\r\nIt is a limitation. If you want to apply transformations to the documents (for each fragment, generate questions, generate a summary, etc.) this is not possible.\r\n\r\nI propose a new version of ParentDocumentRetriever (in the file parent_document_retriever_v2.py for the moment). This version waits `child_transformer` and `child_parent`. It's possible to use it with some splitter.\r\n\r\nI must change the name of the attributs because it's now, some transformer. May be, it's possible to declare the `child_splitter` and `parent_splitter` to be compatible with the previous version. I can do it if you accept the principle of my pull-request.\r\n\r\nThe idea behind this is to improve RAGs, by increasing the versions of embeddings for each fragment.\r\nWith other pull-request, it may be possible to write:\r\n\r\n```\r\nvs = ParentDocumentVectorStore(\r\n    vectorstore=vs,\r\n    docstore=self.docstore,\r\n    id_key=CV_ID_KEY,\r\n    parent_transformer=RecursiveCharacterTextSplitter(),\r\n    child_transformer=DocumentTransformerPipeline(\r\n        transformers=[\r\n            GenerateQuestions.from_llm(llm),\r\n            SummarizeTransformer.from_llm(llm)\r\n        ]\r\n    ),\r\n)\r\n```\r\n\r\nNew version of parent_document_retriever to use \"transformer\" in place of \"splitter\"\r\n\r\n**Tag maintainer:**\r\n@baskaryan\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-18T08:04:30Z",
        "closed_at": null,
        "merged_at": null,
        "body": "** Description**\r\nHelp the llm to generate a correct json format.\r\nThis patch reduces the probability to generating this error.\r\n\r\n*** Issue **\r\nSometime, the json generated with the llm is not correct.  When the llm must generate a list of objects. The last item has an invalid comma.\r\n```\r\n{\"a\":[\"a\",\r\n        \"b\",  # Not, invalid comma at end\r\n        ]\r\n }\r\n```\r\n** Tag maintainer:***\r\n@baskaryan\r\n\r\n**Twitter handler:**\r\npprados\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-18T07:55:06Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Corrected broken link\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-18T07:41:59Z",
        "closed_at": null,
        "merged_at": null,
        "body": "documents=docs not required when making a vector search on an existing Clarifai application\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2023-10-18T07:41:26Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- **Description:** remove duplicated `__all__` variables",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2023-10-18T06:38:38Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** bug fix for sagemakerendpoint streaming, \r\n  - **Issue:** the issue # bug fix for sagemakerendpoint streaming refer (https://aws.amazon.com/blogs/machine-learning/elevating-the-generative-ai-experience-introducing-streaming-support-in-amazon-sagemaker-hosting/),\r\n  - **Dependencies:** same as existing code,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-18T02:28:14Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Current ChatTongyi is not compatible with DashScope API, which will cause error when using it.\r\n  - **Description:** Update tongyi.py to be compatible with DashScope API. Specifically, add input parameter \"prompt\", and update parameter name \"dashscope_api_key\" to \"api_key\".\r\n  - **Issue:** None.\r\n  - **Dependencies:** Nothing new, Tongyi would require DashScope as before.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 203,
        "deletions": 42,
        "changed_files": 3,
        "created_at": "2023-10-17T23:06:28Z",
        "closed_at": "2023-10-17T23:35:11Z",
        "merged_at": "2023-10-17T23:35:11Z",
        "body": "- Update Zep Memory and Retriever docstrings\r\n- Zep Memory Retriever: Add support for native MMR\r\n- Add MMR example to existing ZepRetriever Notebook\r\n\r\n@baskaryan\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 165,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-17T21:51:52Z",
        "closed_at": null,
        "merged_at": null,
        "body": null,
        "comments": 2
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 25,
        "changed_files": 5,
        "created_at": "2023-10-17T21:43:34Z",
        "closed_at": null,
        "merged_at": null,
        "body": "This brings the templates closer to how we develop `langchain`: the same poetry and ruff versions, releasing on manual action instead of using a finicky `if` conditional trigger, etc. Also fixes minor lint and bugs in the workflows.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 12,
        "changed_files": 11,
        "created_at": "2023-10-17T21:37:32Z",
        "closed_at": null,
        "merged_at": null,
        "body": "We don't use any of the new functionality at the moment. Just making sure we don't fall back on versions and fail to benefit from new patches. This is an easy upgrade and it's always harder to upgrade across multiple major versions at once.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 16,
        "changed_files": 15,
        "created_at": "2023-10-17T21:28:39Z",
        "closed_at": "2023-10-18T01:31:44Z",
        "merged_at": "2023-10-18T01:31:44Z",
        "body": "Type hinting `*args` as `List[Any]` means that each positional argument should be a list. Type hinting `**kwargs` as `Dict[str, Any]` means that each keyword argument should be a dict of strings.\n\nThis is almost never what we actually wanted, and doesn't seem to be what we want in any of the cases I'm replacing here.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 54,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2023-10-17T21:23:40Z",
        "closed_at": "2023-10-18T01:22:26Z",
        "merged_at": "2023-10-18T01:22:26Z",
        "body": "Add security note to playwright tool\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 202,
        "deletions": 160,
        "changed_files": 1,
        "created_at": "2023-10-17T20:58:02Z",
        "closed_at": null,
        "merged_at": null,
        "body": "We now require uses to have the pip package `llmonitor` installed. It allows us to have cleaner code and avoid duplicates between our library and our code in Langchain.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-17T20:53:08Z",
        "closed_at": "2023-10-17T21:00:27Z",
        "merged_at": null,
        "body": null,
        "comments": 2
    },
    {
        "merged": false,
        "additions": 103,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-17T20:51:34Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Adds `langchain.runnables.hub.HubRunnable` for pulling configurable objects from the hub",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 86,
        "deletions": 124,
        "changed_files": 10,
        "created_at": "2023-10-17T20:24:07Z",
        "closed_at": "2023-10-17T21:24:51Z",
        "merged_at": "2023-10-17T21:24:51Z",
        "body": "Minor lint dependency version upgrade to pick up latest functionality.\n\nRuff's new v0.1 version comes with lots of nice features, like fix-safety guarantees and a preview mode for not-yet-stable features: https://astral.sh/blog/ruff-v0.1.0\n\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 12,
        "changed_files": 6,
        "created_at": "2023-10-17T20:06:01Z",
        "closed_at": null,
        "merged_at": null,
        "body": "This code also generates warnings when our users' apps hit it, which is annoying and doesn't look great. Let's fix it.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-17T19:44:51Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Update security.md\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 65,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-17T19:44:51Z",
        "closed_at": "2023-10-18T01:31:20Z",
        "merged_at": "2023-10-18T01:31:20Z",
        "body": "The Docs folder changed its structure, and the notebook example for SingleStoreDChatMessageHistory has not been copied to the new place due to a merge conflict. Adding the example to the correct place.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 533,
        "deletions": 17,
        "changed_files": 3,
        "created_at": "2023-10-17T19:28:06Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Add support for async sql database (by utilizing sqlalchemy apis). Could do with some more tests. But, would like some comments while i add tests.\r\n\r\nSample usage with SQLDatabaseChain as follows:\r\n\r\n#!/usr/bin/env python3\r\nimport gevent.monkey\r\ngevent.monkey.patch_all()\r\n\r\nimport asyncio\r\nimport asyncio_gevent\r\nasyncio.set_event_loop_policy(asyncio_gevent.EventLoopPolicy())\r\nimport langchain\r\nlangchain.verbose=True\r\n\r\nfrom langchain.utilities import SQLDatabase\r\nfrom langchain.llms import OpenAI\r\nfrom langchain_experimental.sql import SQLDatabaseChain\r\n\r\nasync def say(what):\r\n    cnt = 0\r\n    while cnt < 5:\r\n        print(what)\r\n        await asyncio.sleep(1)\r\n        cnt += 1\r\n          \r\nasync def do_db():\r\n    db = await SQLDatabase.from_uri_async(\"sqlite+aiosqlite:///Chinook.db\")\r\n    llm = OpenAI(temperature=0, verbose=True)\r\n    db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\r\n    await db_chain.arun(\"How many employees are there?\")\r\n             \r\n\r\nasync def main():\r\n    task1 = asyncio.create_task(say(\"HELLO\"))\r\n    task2 = asyncio.create_task(do_db())\r\n    asyncio.gather(task1, task2)\r\n    \r\nasyncio.run(main())\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-17T19:14:00Z",
        "closed_at": "2023-10-18T01:27:59Z",
        "merged_at": "2023-10-18T01:27:59Z",
        "body": "Add security notes to tools\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1908,
        "deletions": 1845,
        "changed_files": 5,
        "created_at": "2023-10-17T18:25:20Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- **Description:** Adding Pydantic v2 support for OpenAPI Specs \r\n\r\n- **Issue:**\r\n    - OpenAPI spec support was disabled because `openapi-schema-pydantic` doesn't support Pydantic v2:\r\n     #9205\r\n     \r\n     - Caused errors in `get_openapi_chain`\r\n   \r\n    - This may be the cause of #9520.\r\n\r\n- **Tag maintainer:** @eyurtsev\r\n- **Twitter handle:** kreneskyp\r\n\r\n\r\nThe root cause was that `openapi-schema-pydantic` hasn't been updated in some time but [openapi-pydantic](https://github.com/mike-oakley/openapi-pydantic) forked and updated the project.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-17T17:34:30Z",
        "closed_at": "2023-10-17T17:41:43Z",
        "merged_at": "2023-10-17T17:41:43Z",
        "body": "Add security note to recursive loader\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-17T17:06:44Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- **Description:** sqlalchemy create_engine() does not take into account connect_args which are mandatory for managed PGSQL instances on cloud providers (ssl_context for example). \r\nAlso re-enabled create_vector_extension at post_init for using pgvector class seamlessly\r\n- **Tag maintainer:** @baskaryan, @eyurtsev, @hwchase17.\r\n\r\n ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-17T16:38:51Z",
        "closed_at": "2023-10-17T16:47:57Z",
        "merged_at": "2023-10-17T16:47:57Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 103,
        "deletions": 19,
        "changed_files": 2,
        "created_at": "2023-10-17T15:43:44Z",
        "closed_at": "2023-10-17T17:19:27Z",
        "merged_at": "2023-10-17T17:19:27Z",
        "body": "Specify default filter URL in sitemap loader and add a security note\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 433,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-17T15:02:45Z",
        "closed_at": "2023-10-17T18:30:58Z",
        "merged_at": "2023-10-17T18:30:58Z",
        "body": "Description: A large language models developed by Baichuan Intelligent Technology\uff0chttps://www.baichuan-ai.com/home\r\nIssue: None\r\nDependencies: None\r\nTag maintainer:\r\nTwitter handle: ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2023-10-17T14:44:26Z",
        "closed_at": "2023-10-17T14:50:35Z",
        "merged_at": "2023-10-17T14:50:35Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 30,
        "changed_files": 2,
        "created_at": "2023-10-17T12:23:13Z",
        "closed_at": "2023-10-17T14:36:12Z",
        "merged_at": "2023-10-17T14:36:12Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2023-10-17T10:16:59Z",
        "closed_at": "2023-10-17T17:27:29Z",
        "merged_at": "2023-10-17T17:27:29Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 58,
        "deletions": 35,
        "changed_files": 6,
        "created_at": "2023-10-17T07:51:01Z",
        "closed_at": "2023-10-17T14:34:49Z",
        "merged_at": "2023-10-17T14:34:49Z",
        "body": "- Fix some typing issues found while doing that\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2023-10-17T07:25:45Z",
        "closed_at": "2023-10-17T14:30:38Z",
        "merged_at": "2023-10-17T14:30:38Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 78,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-10-17T03:49:45Z",
        "closed_at": "2023-10-17T03:50:15Z",
        "merged_at": "2023-10-17T03:50:15Z",
        "body": null,
        "comments": 3
    },
    {
        "merged": false,
        "additions": 90,
        "deletions": 39,
        "changed_files": 2,
        "created_at": "2023-10-17T03:47:55Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Description: Supported RetryOutputParser & RetryWithErrorOutputParser max_retries\r\n- max_retries: Maximum number of retries to parser.\r\n\r\nIssue: None\r\nDependencies: None\r\nTag maintainer: \r\nTwitter handle: ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 258,
        "changed_files": 3,
        "created_at": "2023-10-17T03:00:58Z",
        "closed_at": "2023-10-17T03:01:12Z",
        "merged_at": "2023-10-17T03:01:12Z",
        "body": "cc @cloudscool, apologies your PR wasn't actually passing CI",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 58,
        "deletions": 5,
        "changed_files": 6,
        "created_at": "2023-10-17T02:45:52Z",
        "closed_at": "2023-10-17T15:45:10Z",
        "merged_at": "2023-10-17T15:45:10Z",
        "body": "This adds security notices to toolkits init, and to several toolkits.\nWe'll need to continue documenting the rest of the toolkits. \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 86,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2023-10-17T02:35:58Z",
        "closed_at": "2023-10-17T14:59:39Z",
        "merged_at": "2023-10-17T14:59:38Z",
        "body": "Add deprecation warnings\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2023-10-17T00:27:23Z",
        "closed_at": null,
        "merged_at": null,
        "body": "## Description\r\nWhen trying to integrate pgvector as a vector store with langchain, I got the following error:\r\n\r\n```\r\n2023-10-16 18:27:54.326 EDT [87858] ERROR:  operator does not exist: json @> unknown at character 106\r\n2023-10-16 18:27:54.326 EDT [87858] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\r\n2023-10-16 18:27:54.326 EDT [87858] STATEMENT:\r\n              SELECT *, embedding <=> $1 as \"_distance\"\r\n              FROM langchain_pg_embedding\r\n              WHERE cmetadata @> $2\r\n              ORDER BY \"_distance\" ASC\r\n              LIMIT $3;\r\n```\r\n\r\n## The problem\r\nFrom my brief research, it appears that the `@>` operator only works with jsonb. So I'm trying to figure out how this ever worked in the first place, but I'm not a postgres expert.\r\n\r\n## Testing / Reproduced\r\n\r\nTo test this, I ran the following against my database after langchain created it and this seemed to fix my issue:\r\n```sql\r\nALTER TABLE langchain_pg_embedding ALTER COLUMN cmetadata SET DATA TYPE jsonb;\r\n```\r\n\r\nI'm using this python version of langchain for running my document loaders and storing my embeddings in PG, but then I have a chat client that's using the langchain-js lib to query it, so I happened to then go see if pgvector had the same problem over there, and it doesn't.\r\nhttps://github.com/langchain-ai/langchainjs/blob/aa9b618786757c301e93caeb3253c56b56d05602/langchain/src/vectorstores/pgvector.ts#L244C38-L244C43\r\n\r\nLet me know if the fix isn't as simple as this or if there's a better solution that should be considered like type casting or something else?\r\n\r\ncc:\r\n@baskaryan, @eyurtsev, @hwchase17\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-16T22:22:11Z",
        "closed_at": "2023-10-17T22:10:20Z",
        "merged_at": "2023-10-17T22:10:20Z",
        "body": "Example\r\n\r\n```\r\nfrom langchain.schema.runnable import RunnableLambda\r\nfrom langsmith import traceable\r\n\r\nchain = RunnableLambda(lambda x: x)\r\n\r\n@traceable(run_type = \"chain\")\r\ndef my_traceable(a):\r\n    chain.invoke(a)\r\nmy_traceable(5)\r\n```\r\n\r\nWould have a nested result.\r\n\r\nThis would NOT work for interleaving chains and traceables. E.g., things like thiswould still not work well\r\n\r\n```\r\nfrom langchain.schema.runnable import RunnableLambda\r\nfrom langsmith import traceable\r\n\r\n@traceable()\r\ndef other_traceable(a):\r\n    return a\r\n\r\ndef foo(x):\r\n    return other_traceable(x)\r\n    \r\nchain = RunnableLambda(foo)\r\n\r\n@traceable(run_type = \"chain\")\r\ndef my_traceable(a):\r\n    chain.invoke(a)\r\nmy_traceable(5)\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 191,
        "deletions": 128,
        "changed_files": 3,
        "created_at": "2023-10-16T22:00:38Z",
        "closed_at": "2023-10-16T23:44:13Z",
        "merged_at": "2023-10-16T23:44:13Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 334,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2023-10-16T20:57:55Z",
        "closed_at": "2023-10-17T00:08:05Z",
        "merged_at": "2023-10-17T00:08:05Z",
        "body": "  - **Description:** added together.xyz as an LLM provider, \r\n  - **Issues:** fix some linting issues\r\n  - twitter handle @jilijeanlouis \r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access, \u2705\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory. \u274c => classic LLM provider\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-16T20:36:27Z",
        "closed_at": "2023-10-16T23:54:21Z",
        "merged_at": "2023-10-16T23:54:21Z",
        "body": "Removes the check of `model.is_quantized` and adds more robust way of checking for 4bit and 8bit quantization in the `huggingface_pipeline.py` script. I had to make the original change on the outdated version of `transformers`, because the models had this property before. Seems redundant now.\r\n\r\nFixes: https://github.com/langchain-ai/langchain/issues/11809 and https://github.com/langchain-ai/langchain/issues/11759",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-16T20:34:38Z",
        "closed_at": "2023-10-16T23:55:46Z",
        "merged_at": "2023-10-16T23:55:45Z",
        "body": "  - **Description:** added examples to Vertex chat models as optional class attributes, so that a model with examples can be used inside a chain\r\n  - **Twitter handle:** lkuligin",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 363,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-16T20:26:08Z",
        "closed_at": "2023-10-16T23:01:48Z",
        "merged_at": "2023-10-16T23:01:47Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 184,
        "deletions": 286,
        "changed_files": 2,
        "created_at": "2023-10-16T20:21:57Z",
        "closed_at": "2023-10-16T23:44:26Z",
        "merged_at": "2023-10-16T23:44:26Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-16T20:11:05Z",
        "closed_at": "2023-10-17T19:20:40Z",
        "merged_at": null,
        "body": "#### Description\r\nThis PR adds an option to the RetrievalQA chains to use provided documents in `_call()` and`_acall()` methods like: `qa_chain({\"query\": question, \"from_documents\": documents})` where documents is `List[Document]`\r\n\r\nCurrently there is no way to reuse documents found from a `similarity_search` in a `RetrievalQA`. This PR enables the following sequence:\r\n1. User embeds query and gets documents\r\n2. User implements desired logic based on documents\r\n3. User calls `RetrievalQA` without needing to re-embed query to find relevant documents.\r\n\r\nThis option will also be helpful if the user wants to gather documents in any custom way, like combining from different sources.\r\n\r\n\r\n#### Usage\r\n\r\n\r\n\r\nExample Usage:\r\n```\r\n\r\nqa_chain  =  RetrievalQA.from_chain_type(\r\n     llm=llm,\r\n     retriever=vector_store.as_retriever(),\r\n)\r\n\r\ndocuments = vector_store.similarity_search(\"Is the sky blue?\")\r\n\r\nif \"blue\" in documents[0].page_content:\r\n\t# Reuse documents in LLM call since they passed our condition\r\n\tresponse  =  qa_chain({\"query\": question, \"from_documents\": documents})\r\n\t\r\n#True\r\nresponse[\"source_documents\"] == documents \r\n```\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 105,
        "deletions": 152,
        "changed_files": 4,
        "created_at": "2023-10-16T20:10:10Z",
        "closed_at": "2023-10-16T20:37:52Z",
        "merged_at": "2023-10-16T20:37:52Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 220,
        "deletions": 126,
        "changed_files": 4,
        "created_at": "2023-10-16T20:08:58Z",
        "closed_at": "2023-10-17T00:05:13Z",
        "merged_at": "2023-10-17T00:05:13Z",
        "body": "Replace this entire comment with:\r\n  - **Description:** Added a retriever based on multi-turn Vertex AI Search\r\n  - **Twitter handle:** lkuligin",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2023-10-16T19:34:57Z",
        "closed_at": "2023-10-17T00:08:29Z",
        "merged_at": "2023-10-17T00:08:29Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-16T19:12:47Z",
        "closed_at": "2023-10-16T21:41:21Z",
        "merged_at": "2023-10-16T21:41:21Z",
        "body": "Add security markdown file\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 259,
        "deletions": 91,
        "changed_files": 2,
        "created_at": "2023-10-16T19:06:33Z",
        "closed_at": "2023-10-16T19:35:18Z",
        "merged_at": "2023-10-16T19:35:18Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-16T19:03:09Z",
        "closed_at": "2023-10-17T01:12:14Z",
        "merged_at": "2023-10-17T01:12:13Z",
        "body": "Add security notice to file management tool\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-16T18:41:16Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 386,
        "deletions": 133,
        "changed_files": 2,
        "created_at": "2023-10-16T18:17:29Z",
        "closed_at": "2023-10-16T18:34:32Z",
        "merged_at": "2023-10-16T18:34:32Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-16T17:37:10Z",
        "closed_at": "2023-10-16T21:21:37Z",
        "merged_at": "2023-10-16T21:21:37Z",
        "body": "Adding description of the `View deployment` button on the PR page. This nice feature was not documented.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2023-10-16T16:10:15Z",
        "closed_at": "2023-10-16T16:12:03Z",
        "merged_at": "2023-10-16T16:12:03Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 108,
        "deletions": 10,
        "changed_files": 10,
        "created_at": "2023-10-16T15:43:24Z",
        "closed_at": "2023-10-16T16:23:49Z",
        "merged_at": "2023-10-16T16:23:49Z",
        "body": "Add security considerations to existing graph tools.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-16T15:35:33Z",
        "closed_at": "2023-10-17T00:10:32Z",
        "merged_at": "2023-10-17T00:10:32Z",
        "body": "  - **Description:** added one missing word to a doc, \r\n  - **Dependencies:** N/A\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 53,
        "deletions": 45,
        "changed_files": 3,
        "created_at": "2023-10-16T15:10:55Z",
        "closed_at": "2023-10-17T00:42:10Z",
        "merged_at": "2023-10-17T00:42:10Z",
        "body": "**Description:**\r\nWhile working on the Docusaurus site loader #9138, I noticed some outdated docs and tests for the Sitemap Loader. \r\n\r\n**Issue:** \r\nThis is tangentially related to #6691 in reference to doc links. I plan on digging in to a few of these issue when I find time next.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-16T14:46:17Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- \r\n  - **Description:** removed redondant link, replaced it with Meta's LLaMA repo, add resources for models' hardware requirements, \r\n  - **Issue:** None,\r\n  - **Dependencies:** None,\r\n  - **Tag maintainer:** None,\r\n  - **Twitter handle:** @ElliotAlladaye\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-16T13:46:20Z",
        "closed_at": "2023-10-17T01:03:47Z",
        "merged_at": "2023-10-17T01:03:47Z",
        "body": "  - **Description:** While reading the docs (https://python.langchain.com/docs/integrations/providers/huggingface), I noticed the notebook linked in https://python.langchain.com/docs/use_cases/evaluation/huggingface_datasets.html was giving back 404. I made a search in the docs to see whether it was available, so this PR updates the link in the docs.\r\n  - **Issue:** I haven't opened an issue for this change.\r\n  - **Dependencies:** -\r\n  - **Tag maintainer:** -,\r\n  - **Twitter handle:** -\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2023-10-16T12:56:24Z",
        "closed_at": "2023-10-17T01:01:48Z",
        "merged_at": "2023-10-17T01:01:48Z",
        "body": "This patch fixes some spelling typo in learned_prompt_optimization.ipynb. \r\nIt only changed messages, no logic changed.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-16T11:58:34Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** Experiencing a 403 Forbidden error when using the RecursiveUrlLoader on certain websites, and that this issue is resolved when we manually set a User-Agent in the headers. The WebBaseLoader in LangChain has a default User-Agent set in the session headers but RecursiveUrlLoader doesn't have default User-Agent. Updated  RecursiveUrlLoader code to include default user-agent, if it is not provided.\r\n  - **Issue:** This fixes 403 Forbidden error on certain websites. This code update will solve the issue mentioned in the link https://github.com/langchain-ai/langchain/issues/11540,https://github.com/langchain-ai/langchain/issues/11541.\r\n  - **Dependencies:** fake_useragent library is needed,\r\n  - **Tag maintainer:** @baskaryan, @eyurtsev, @hwchase17,\r\n  ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 187,
        "deletions": 67,
        "changed_files": 4,
        "created_at": "2023-10-16T11:03:17Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** \r\n - Improves lancedb integration by making it easier to use - now you don't require to create tables manually and pass it in the constructor, although that is still backwards compatible.\r\n - Bug fix - pandas was being used even though its not a dependency for lancedb or langchain\r\n\r\n  - **Tag maintainer:** \r\n  @baskaryan\r\n\r\n  - **Twitter handle:** @loldedxd\r\n  \r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 931,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2023-10-16T08:22:23Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n### Description: \r\nTo provide an eas llm service access methods in this pull request by impletementing `PaiEasEndpoint` and `PaiEasChatEndpoint` classes in `langchain.llms` and `langchain.chat_models` modules. Base on this pr, langchain users can build up a chain to  call remote eas llm service and get the llm inference results.\r\n\r\n### About EAS Service\r\nEAS is a Alicloud product on Alibaba Cloud Machine Learning Platform for AI which is short for AliCloud PAI. EAS provides model inference deployment services for the users. We build up a llm inference services on EAS with a general llm docker images. Therefore, end users can quickly setup their llm remote instances to load majority of the hugginface llm models, and serve as a backend for most of the llm apps. \r\n\r\n### Dependencies\r\nThis pr does't involve any new dependencies.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-16T07:46:02Z",
        "closed_at": "2023-10-16T07:50:54Z",
        "merged_at": "2023-10-16T07:50:54Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 465,
        "deletions": 127,
        "changed_files": 4,
        "created_at": "2023-10-16T07:38:54Z",
        "closed_at": "2023-10-17T01:07:24Z",
        "merged_at": "2023-10-17T01:07:24Z",
        "body": "Hello Folks,\r\n\r\nAlibaba Cloud OpenSearch has released a new version of the vector storage engine, which has significantly improved performance compared to the previous version. At the same time, the sdk has also undergone changes, requiring adjustments alibaba opensearch vector store code  to adapt.\r\n\r\nThis PR includes:\r\n\r\nAdapt to the latest version of Alibaba Cloud OpenSearch API.\r\nMore comprehensive unit testing.\r\nImprove documentation.\r\n\r\nI have read your contributing guidelines. And I have passed the tests below\r\n\r\n- [x] make format\r\n- [x]  make lint\r\n- [x]  make coverage\r\n- [x]  make test",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 274,
        "deletions": 193,
        "changed_files": 44,
        "created_at": "2023-10-16T07:30:30Z",
        "closed_at": "2023-10-17T18:42:22Z",
        "merged_at": "2023-10-17T18:42:22Z",
        "body": "\r\n- **Description:** \r\n  - Add `.delete` to myscale vector store. \r\n  - Revised vector store notebooks\r\n- **Tag maintainer:** @baskaryan \r\n- **Twitter handle:** @myscaledb @mpsk_liu \r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-16T03:43:29Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** update Weaviate to support multi tenancy\r\n  - **Issue:** 9956\r\n  - **Dependencies:** \r\n  - **Tag maintainer:** hwchase17\r\n  - **Twitter handle:** dsx1986_\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1277,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2023-10-16T03:17:48Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Issue: #11763\r\nDependencies: N/A\r\n\r\nI have run 'make format' 'make lint' and 'make test'\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 599,
        "deletions": 126,
        "changed_files": 3,
        "created_at": "2023-10-15T21:23:07Z",
        "closed_at": "2023-10-15T21:59:45Z",
        "merged_at": "2023-10-15T21:59:45Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 763,
        "deletions": 138,
        "changed_files": 4,
        "created_at": "2023-10-15T21:07:56Z",
        "closed_at": "2023-10-15T21:59:36Z",
        "merged_at": "2023-10-15T21:59:36Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 29,
        "changed_files": 1,
        "created_at": "2023-10-15T20:15:19Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-15T19:32:36Z",
        "closed_at": null,
        "merged_at": null,
        "body": "updated readme\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 43,
        "deletions": 5,
        "changed_files": 8,
        "created_at": "2023-10-15T16:53:24Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Add an `exclude_glob` option to exclude some files or dirs from the main glob. Sample use case: a directory structure like this\r\n```\r\nmain_directory/\r\n    backup/ # Don't want to load from here\r\n    file_directory_1/\r\n    file_directory_2/\r\n    ...\r\n``` \r\n(inspired by [LogSeq](https://logseq.com/) data structure)",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-15T16:29:43Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Thanks for building Langchain. \r\n\r\nAn small contribution: \r\n\r\n  - **Description:** Fix broken link for `modules/retrieval/retrievers` `state_of_the_union.txt` file in getting started section.  \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** : N/A\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** @laura_uzcategui\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 215,
        "deletions": 43,
        "changed_files": 2,
        "created_at": "2023-10-15T15:37:56Z",
        "closed_at": "2023-10-15T16:00:08Z",
        "merged_at": "2023-10-15T16:00:08Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-15T13:48:52Z",
        "closed_at": "2023-10-16T10:03:45Z",
        "merged_at": null,
        "body": "- Include `/wiki` to URL path\r\n- My issue: [11842](https://github.com/langchain-ai/langchain/issues/11824)\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-15T12:14:18Z",
        "closed_at": "2023-10-17T01:43:15Z",
        "merged_at": "2023-10-17T01:43:15Z",
        "body": "Fixed a typo : \r\n\r\n\"asyncrhonized\" > \"asynchronized\"\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-15T12:10:42Z",
        "closed_at": "2023-10-17T01:43:29Z",
        "merged_at": "2023-10-17T01:43:29Z",
        "body": "Fixed a typo : \r\n\r\nbenifits -> benefits\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-15T06:50:05Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\n\nReplace this entire comment with:\n  - **Description:** a description of the change, \n  - **Issue:** the issue # it fixes (if applicable),\n  - **Dependencies:** any dependencies required for this change,\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\n\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\n\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\n\nIf you're adding a new integration, please include:\n  1. a test for the integration, preferably unit tests that do not rely on network access,\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\n\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\n -->\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 562,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2023-10-14T20:27:11Z",
        "closed_at": "2023-10-14T23:03:58Z",
        "merged_at": "2023-10-14T23:03:58Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 287,
        "deletions": 145,
        "changed_files": 5,
        "created_at": "2023-10-14T13:16:34Z",
        "closed_at": "2023-10-17T01:46:20Z",
        "merged_at": "2023-10-17T01:46:20Z",
        "body": "## Description\r\n\r\n\r\n\r\n| Tool         | Original Tool Name       |\r\n|-----------------------------|---------------------------|\r\n| open-meteo-api              | Open Meteo API            |\r\n| news-api                    | News API                  |\r\n| tmdb-api                    | TMDB API                  |\r\n| podcast-api                 | Podcast API               |\r\n| golden_query                | Golden Query              |\r\n| dall-e-image-generator      | Dall-E Image Generator    |\r\n| twilio                      | Text Message              |\r\n| searx_search_results        | Searx Search Results      |\r\n| dataforseo                  | DataForSeo Results JSON   |\r\n\r\nWhen using these tools through `load_tools`, I encountered the following validation error:\r\n\r\n```console\r\nopenai.error.InvalidRequestError: 'TMDB API' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'functions.0.name'\r\n```\r\n\r\nIn order to avoid this error, I replaced spaces with hyphens in the tool names:\r\n\r\n| Tool           | Corrected Tool Name       |\r\n|-----------------------------|---------------------------|\r\n| open-meteo-api              | Open-Meteo-API            |\r\n| news-api                    | News-API                  |\r\n| tmdb-api                    | TMDB-API                  |\r\n| podcast-api                 | Podcast-API               |\r\n| golden_query                | Golden-Query              |\r\n| dall-e-image-generator      | Dall-E-Image-Generator    |\r\n| twilio                      | Text-Message              |\r\n| searx_search_results        | Searx-Search-Results      |\r\n| dataforseo                  | DataForSeo-Results-JSON   |\r\n\r\nThis correction resolved the validation error.\r\n\r\nAdditionally, a unit test, `tests/unit_tests/schema/runnable/test_runnable.py::test_stream_log_retriever`, was failing at random. Upon further investigation, I confirmed that the failure was not related to the above-mentioned changes. The `stream_log` variable was generating the order of logs in two ways at random The reason for this behavior is unclear, but in the assertion, I included both possible orders to account for this variability.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2023-10-14T12:28:42Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Splitted get function in 3 functions to fix it cyclomatic complexity from C to B and A",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-14T09:17:33Z",
        "closed_at": null,
        "merged_at": null,
        "body": "remove redundant a\r\nlangchain > LangChain",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2023-10-14T07:14:45Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:** The new version now pops the buffer when the messages are requested, keeping the original messages safe inside the chat history.\r\n\r\nThe scenario where the previous version did not work for me was with DynamoDB memory implementation, since I was loading the chat history on initialization only and never called the save_context method before my first llm call.\r\nThis version now also keeps the original chat history intact, which was desirable for my case.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-14T05:16:02Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** Updated the `_dalle_image_url` method to return a list of URLs if self.n>1, \r\n  - **Issue:** #10691,\r\n  - **Dependencies:** unsure,\r\n  - **Tag maintainer:** @eyurtsev,\r\n  - **Twitter handle:** @silvhua\r\n\r\nI am new to development and do not know how to do any of the make format, make lint and make test steps or how to test the code locally. I would appreciate help with that.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-14T05:04:57Z",
        "closed_at": null,
        "merged_at": null,
        "body": "\r\n  - **Description:** Fix the integration library import for the Oobagooba Textgeneration webui\r\n\r\nSelf explanatory fix - it seems like the paths were changed.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 11013,
        "deletions": 11694,
        "changed_files": 145,
        "created_at": "2023-10-14T04:55:00Z",
        "closed_at": "2023-10-15T19:20:59Z",
        "merged_at": "2023-10-15T19:20:58Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-14T02:49:18Z",
        "closed_at": "2023-10-14T02:50:23Z",
        "merged_at": "2023-10-14T02:50:23Z",
        "body": "customize readthedocs config so that we can parallelize the api docs build",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-14T02:33:39Z",
        "closed_at": "2023-10-17T02:07:04Z",
        "merged_at": "2023-10-17T02:07:04Z",
        "body": "trasform -> transform",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-14T02:17:26Z",
        "closed_at": "2023-10-17T02:07:21Z",
        "merged_at": "2023-10-17T02:07:21Z",
        "body": "I have fixed some typos in file `cookbook/Semi_structured_and_multi_modal_RAG.ipynb`. I kindly request the repo maintainers to review and merge it. Thanks!",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-10-14T02:16:57Z",
        "closed_at": "2023-10-17T02:08:14Z",
        "merged_at": null,
        "body": "I have fixed some typos in file `cookbook/learned_prompt_optimization.ipynb`. I kindly request the repo maintainers to review and merge it. Thanks!",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-14T02:16:13Z",
        "closed_at": "2023-10-17T02:09:05Z",
        "merged_at": "2023-10-17T02:09:05Z",
        "body": "I have fixed some typos in file `cookbook/self_query_hotel_search.ipynb`. I kindly request the repo maintainers to review and merge it. Thanks!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-14T02:14:28Z",
        "closed_at": "2023-10-17T02:09:21Z",
        "merged_at": "2023-10-17T02:09:21Z",
        "body": "I have fixed some typos in file `cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb`. I kindly request the repo maintainers to review and merge it. Thanks!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-14T02:14:07Z",
        "closed_at": "2023-10-17T02:10:40Z",
        "merged_at": "2023-10-17T02:10:40Z",
        "body": "I have fixed some typos in file `cookbook/sales_agent_with_context.ipynb`. I kindly request the repo maintainers to review and merge it. Thanks!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 92,
        "deletions": 140,
        "changed_files": 6,
        "created_at": "2023-10-14T00:43:57Z",
        "closed_at": "2023-10-17T02:14:21Z",
        "merged_at": "2023-10-17T02:14:21Z",
        "body": "The current ToC on the index page and on navbar don't match. Page titles and Titles in ToC doesn't match\r\nChanges:\r\n- made ToCs equal\r\n- made titles equal\r\n- updated some page formattings.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-14T00:24:13Z",
        "closed_at": "2023-10-14T07:39:24Z",
        "merged_at": "2023-10-14T07:39:24Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 298,
        "deletions": 291,
        "changed_files": 47,
        "created_at": "2023-10-13T22:25:49Z",
        "closed_at": "2023-10-17T02:18:58Z",
        "merged_at": null,
        "body": null,
        "comments": 2
    },
    {
        "merged": false,
        "additions": 49,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-13T20:45:32Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 134,
        "changed_files": 4,
        "created_at": "2023-10-13T20:36:43Z",
        "closed_at": "2023-10-13T20:58:27Z",
        "merged_at": "2023-10-13T20:58:27Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-13T20:20:01Z",
        "closed_at": "2023-10-13T20:31:36Z",
        "merged_at": "2023-10-13T20:31:36Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-13T19:41:18Z",
        "closed_at": "2023-10-13T20:34:28Z",
        "merged_at": "2023-10-13T20:34:28Z",
        "body": "Hi,\r\n\r\nAfter submitting https://github.com/langchain-ai/langchain/pull/11357, we realized that the notebooks are moved to a new location. Sending a new PR to update the doc.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-13T18:54:56Z",
        "closed_at": "2023-10-13T19:01:22Z",
        "merged_at": "2023-10-13T19:01:22Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1171,
        "deletions": 0,
        "changed_files": 20,
        "created_at": "2023-10-13T16:44:57Z",
        "closed_at": "2023-10-13T21:36:44Z",
        "merged_at": "2023-10-13T21:36:44Z",
        "body": "See for contex https://github.com/langchain-ai/langchain/discussions/11680\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-13T16:42:46Z",
        "closed_at": "2023-10-13T18:09:55Z",
        "merged_at": "2023-10-13T18:09:55Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2023-10-13T13:10:38Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** Added the parameter for a possibility to change a language model in SpacyEmbeddings. The default value is still the same: \"en_core_web_sm\", so it shouldn't affect a code which previously did not specify this parameter, but it is not hard-coded anymore and easy to change in case you want to use it with other languages or models.\r\n  \r\n  - **Issue:** At Barcelona Supercomputing Center in Aina project (https://github.com/projecte-aina), a project for Catalan Language Models and Resources, we would like to use Langchain for one of our current projects and we would like to comment that Langchain, while being a very powerful and useful open-source tool, is pretty much focused on English language. We would like to contribute to make it a bit more adaptable for using with other languages.\r\n  \r\n  - **Dependencies:**  This change requires the Spacy library and a language model, specified in the model parameter.\r\n  - **Tag maintainer:** @dev2049\r\n  - **Twitter handle:** @projecte_aina\r\n\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-13T11:50:15Z",
        "closed_at": "2023-10-16T11:36:29Z",
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** Default User-Agent added to RecursiveUrlLoader headers, \r\n  - **Issue:**  Fixes the following issue raised. https://github.com/langchain-ai/langchain/issues/11541 ,\r\n  - **Dependencies:** Needed fake_useragent python library . pip install fake_useragent,\r\n  - **Tag maintainer:** @baskaryan, @eyurtsev, @hwchase17,\r\n ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-10-13T10:57:00Z",
        "closed_at": "2023-10-17T03:28:32Z",
        "merged_at": "2023-10-17T03:28:32Z",
        "body": "Hi,\r\n\r\nI recently experimented with grammar-based sampling and discovered two methods for speeding up the creation of gbnf grammar files:\r\n1. [Online grammar generator app](https://github.com/ggerganov/llama.cpp/discussions/2494) introduced [here](https://github.com/ggerganov/llama.cpp/discussions/2494)\r\n2. [Script](https://github.com/ggerganov/llama.cpp/blob/master/examples/json-schema-to-grammar.py) for parsing json schema to gbnf grammar\r\n\r\nI believe it is a good idea to include the information that leads to them in the `llama-cpp` notebook.\r\n\r\n***\r\n\r\nCodespell check fails but due to the unrelated script ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2023-10-13T10:48:24Z",
        "closed_at": "2023-10-15T20:15:06Z",
        "merged_at": "2023-10-15T20:15:06Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 258,
        "changed_files": 3,
        "created_at": "2023-10-13T10:41:51Z",
        "closed_at": "2023-10-13T15:23:15Z",
        "merged_at": "2023-10-13T15:23:15Z",
        "body": "Reverts langchain-ai/langchain#11714\r\n\r\nThis has linting and formatting issues, plus it's added to chat models folder but doesn't subclass Chat Model base class",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-13T07:47:38Z",
        "closed_at": null,
        "merged_at": null,
        "body": " - **Description:** Some organisations expose Azure OpenAI endpoints via some proxies that need additional HTTP headers. This PR supports for that by allowing the user to set custom headers when initialising the AzureOpenAI class. These custom headers can be used when making requests.\r\n  - **Issue:** it aims to fix the issue #11593\r\n  - **Dependencies:** - \r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2023-10-13T07:07:07Z",
        "closed_at": "2023-10-17T02:25:47Z",
        "merged_at": "2023-10-17T02:25:47Z",
        "body": "Description: Supported OutputFixingParser max_retries\r\n - max_retries: Maximum number of retries to parser.\r\n\r\nIssue: None\r\nDependencies: None\r\nTag maintainer: @baskaryan\r\nTwitter handle: @JohnMai95",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 258,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-13T06:56:11Z",
        "closed_at": "2023-10-17T02:27:36Z",
        "merged_at": "2023-10-17T02:27:36Z",
        "body": "Defautlt -->Default",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-13T01:58:28Z",
        "closed_at": "2023-10-13T05:36:31Z",
        "merged_at": "2023-10-13T05:36:31Z",
        "body": "changed > to over ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-13T00:14:22Z",
        "closed_at": "2023-10-13T00:24:06Z",
        "merged_at": "2023-10-13T00:24:06Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 22,
        "changed_files": 18,
        "created_at": "2023-10-12T23:54:17Z",
        "closed_at": "2023-10-13T05:36:07Z",
        "merged_at": "2023-10-13T05:36:07Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-12T23:30:39Z",
        "closed_at": "2023-10-12T23:31:09Z",
        "merged_at": "2023-10-12T23:31:09Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 613,
        "changed_files": 1,
        "created_at": "2023-10-12T23:26:47Z",
        "closed_at": "2023-10-12T23:26:55Z",
        "merged_at": "2023-10-12T23:26:55Z",
        "body": "committed old doc in wrong place",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 106,
        "deletions": 93,
        "changed_files": 11,
        "created_at": "2023-10-12T22:59:35Z",
        "closed_at": "2023-10-14T16:29:30Z",
        "merged_at": "2023-10-14T16:29:30Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-10-12T22:55:59Z",
        "closed_at": "2023-10-13T00:01:19Z",
        "merged_at": "2023-10-13T00:01:19Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n\r\ncc @baskaryan ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 919,
        "deletions": 890,
        "changed_files": 3,
        "created_at": "2023-10-12T22:25:36Z",
        "closed_at": "2023-10-12T22:46:55Z",
        "merged_at": "2023-10-12T22:46:55Z",
        "body": "cc @leo-gan ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 149,
        "deletions": 333,
        "changed_files": 7,
        "created_at": "2023-10-12T22:15:04Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- Only works for Data stores with Advanced Website Indexing\r\n  - https://cloud.google.com/generative-ai-app-builder/docs/about-advanced-features\r\n- Minor restructuring - Follow up to #10513\r\n  - Remove outdated docs (readded in https://github.com/langchain-ai/langchain/pull/11620)\r\n  - Move legacy class into new py file to clean up the directory\r\n    - Shouldn't cause backwards compatibility issues as the import works the same way for users ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 59,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2023-10-12T19:53:50Z",
        "closed_at": "2023-10-12T21:04:01Z",
        "merged_at": null,
        "body": "**Description**:\r\n\r\nTo support a wider range of expected metadata values, we now serialize these values to JSON when storing in Momento Vector Index. Specifically, in the add method, values are dumped as JSON strings using `json.dumps`. During the search operation, we deserialize them using `json.loads`.\r\n\r\n**Testing**:\r\n\r\nWe updated the integration tests to exercise this new behavior.\r\n\r\n**Maintainers**:\r\n\r\n@baskaryan who reviewed the original MVI PR.\r\n\r\n**Twitter handle:**\r\n\r\n@momentohq for Momento Vector Index vector store introduction",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 264,
        "deletions": 201,
        "changed_files": 7,
        "created_at": "2023-10-12T19:45:59Z",
        "closed_at": null,
        "merged_at": null,
        "body": "This PR replaces the previous `Intent` check with the new `Prompt Safety` check. The logic and steps to enable chain moderation via the Amazon Comprehend service, allowing you to detect and redact PII, Toxic, and Prompt Safety information in the LLM prompt or answer remains unchanged.\r\nThis implementation updates the code and configuration types with respect to `Prompt Safety`.\r\n\r\n\r\n### Usage sample\r\n\r\n```python\r\nfrom langchain_experimental.comprehend_moderation import (BaseModerationConfig, \r\n                                 ModerationPromptSafetyConfig, \r\n                                 ModerationPiiConfig, \r\n                                 ModerationToxicityConfig\r\n)\r\n\r\npii_config = ModerationPiiConfig(\r\n    labels=[\"SSN\"],\r\n    redact=True,\r\n    mask_character=\"X\"\r\n)\r\n\r\ntoxicity_config = ModerationToxicityConfig(\r\n    threshold=0.5\r\n)\r\n\r\nprompt_safety_config = ModerationPromptSafetyConfig(\r\n    threshold=0.5\r\n)\r\n\r\nmoderation_config = BaseModerationConfig(\r\n    filters=[pii_config, toxicity_config, prompt_safety_config]\r\n)\r\n\r\ncomp_moderation_with_config = AmazonComprehendModerationChain(\r\n    moderation_config=moderation_config, #specify the configuration\r\n    client=comprehend_client,            #optionally pass the Boto3 Client\r\n    verbose=True\r\n)\r\n\r\ntemplate = \"\"\"Question: {question}\r\n\r\nAnswer:\"\"\"\r\n\r\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\r\n\r\nresponses = [\r\n    \"Final Answer: A credit card number looks like 1289-2321-1123-2387. A fake SSN number looks like 323-22-9980. John Doe's phone number is (999)253-9876.\", \r\n    \"Final Answer: This is a really shitty way of constructing a birdhouse. This is fucking insane to think that any birds would actually create their motherfucking nests here.\"\r\n]\r\nllm = FakeListLLM(responses=responses)\r\n\r\nllm_chain = LLMChain(prompt=prompt, llm=llm)\r\n\r\nchain = ( \r\n    prompt \r\n    | comp_moderation_with_config \r\n    | {llm_chain.input_keys[0]: lambda x: x['output'] }  \r\n    | llm_chain \r\n    | { \"input\": lambda x: x['text'] } \r\n    | comp_moderation_with_config \r\n)\r\n\r\ntry:\r\n    response = chain.invoke({\"question\": \"A sample SSN number looks like this 123-456-7890. Can you give me some more samples?\"})\r\nexcept Exception as e:\r\n    print(str(e))\r\nelse:\r\n    print(response['output'])\r\n\r\n```\r\n\r\n### Output\r\n\r\n```python\r\n> Entering new AmazonComprehendModerationChain chain...\r\nRunning AmazonComprehendModerationChain...\r\nRunning pii Validation...\r\nRunning toxicity Validation...\r\nRunning prompt safety Validation...\r\n\r\n> Finished chain.\r\n\r\n\r\n> Entering new AmazonComprehendModerationChain chain...\r\nRunning AmazonComprehendModerationChain...\r\nRunning pii Validation...\r\nRunning toxicity Validation...\r\nRunning prompt safety Validation...\r\n\r\n> Finished chain.\r\nFinal Answer: A credit card number looks like 1289-2321-1123-2387. A fake SSN number looks like XXXXXXXXXXXX John Doe's phone number is (999)253-9876.\r\n```\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 69,
        "deletions": 33,
        "changed_files": 5,
        "created_at": "2023-10-12T19:19:02Z",
        "closed_at": "2023-10-13T20:31:21Z",
        "merged_at": "2023-10-13T20:31:21Z",
        "body": "  - **Description:**  added support for `candidate_count` parameter on Vertex",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 128,
        "deletions": 7,
        "changed_files": 7,
        "created_at": "2023-10-12T18:55:45Z",
        "closed_at": "2023-10-13T16:48:24Z",
        "merged_at": "2023-10-13T16:48:24Z",
        "body": "To match change in js here https://github.com/langchain-ai/langchainjs/pull/2892\r\n\r\nSome integration tests need a bit more work in experimental:\r\n![Screenshot 2023-10-12 at 12 02 49 PM](https://github.com/langchain-ai/langchain/assets/9557659/262d7d22-c405-40e9-afef-669e8d585307)\r\n\r\nPretty sure the sqldatabase ones are an actual regression or change in interface because it's returning a placeholder.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-12T18:18:47Z",
        "closed_at": "2023-10-13T19:03:33Z",
        "merged_at": "2023-10-13T19:03:33Z",
        "body": "  - **Description:**\r\n    -  If the Elasticsearch field used for Langchain > Document.page_content is missing because the specific document is \r\n        somehow malformed fail gracefully.\r\n\r\n  - **Tag maintainer:** \r\n    - @joemcelroy\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 28,
        "changed_files": 6,
        "created_at": "2023-10-12T18:02:11Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Commit Description:\r\nIn this update, several documentation sections were improved by correcting typos and enhancing overall clarity. The changes made include fixing spelling and grammar issues, refining sentence structures, and providing more informative content where necessary. These improvements aim to make the documentation more user-friendly and easier to understand.\r\n\r\nFiles changed for better clarity of text and typo fix : - \r\nlangchain\\docs\\docs\\modules\\agents\\tools\\index.mdx\r\nlangchain\\docs\\docs\\modules\\agents\\toolkits\\index.mdx\r\nlangchain\\docs\\docs\\modules\\agents\\how_to\\mrkl.mdx\r\nlangchain\\docs\\docs\\modules\\agents\\how_to\\custom_llm_chat_agent.mdx\r\nlangchain\\docs\\docs\\modules\\agents\\how_to\\custom_llm_agent.mdx\r\nlangchain\\docs\\docs\\modules\\agents\\agent_types\\index.mdx\r\n\r\nSome examples of the fix : - \r\n1. Added \"For documentation on built-in toolkit integrations, visit\" to the info box.\r\nCorrected \"convenience\" to \"convenient\" for proper adjective usage.\r\n\r\n2. Added \"For documentation on built-in tool integrations, visit\" to the info box.\r\nChanged \"Get started\" to \"Getting Started\" for consistency.\r\nMade the sentence structure in the \"Getting Started\" section more consistent and clear.\r\nCapitalized \"Getting Started\" for section title consistency.\r\nClarified the loading of tools by rephrasing the sentence.\r\n\r\n3. Added \"This example uses\" for clarity.\r\nAdded commas after \"MRKL system\" and \"Chinook database\" for better readability.\r\nClarified the setup instructions by breaking the sentence into two parts.\r\nCapitalized \"Using a Chat Model\" for consistency.\r\n\r\n4. \"goes through\" changed to \"explains.\"\r\nAdded periods at the end of each bullet point for consistency.\r\nCapitalized the \"Agent\" in \"Custom LLM Chat Agent.\"\r\nAdded the word \"components\" to clarify the list.\r\nCorrected the numbering of components.\r\n\r\n5. \"goes through\" changed to \"explains\"\r\nAdded periods at the end of each bullet point for consistency.\r\nCapitalized the \"Agent\" in \"Custom LLM Agent.\"\r\nAdded the word \"components\" to clarify the list.\r\nMade some minor wording adjustments for clarity and consistency.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 232,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-12T17:11:25Z",
        "closed_at": "2023-10-12T17:48:46Z",
        "merged_at": "2023-10-12T17:48:46Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 68,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-12T17:10:38Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** Add `Memorize` tool\r\n  - **Tag maintainer:** @hwchase17\r\n\r\nThis PR added a new tool `Memorize` so that an agent can use it to fine-tune itself. This tool requires `TrainableLLM` introduced in #11721\r\n\r\nDEMO: https://github.com/Preemo-Inc/gradient-langchain-tool-demo/tree/6a9003d5db8db03673ad8b205f4d00cf0d96b56b\r\n![image](https://github.com/langchain-ai/langchain/assets/601530/d6f0cb45-54df-4dcf-b143-f8aefb1e76e3)\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 108,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2023-10-12T17:09:27Z",
        "closed_at": "2023-10-13T00:38:34Z",
        "merged_at": "2023-10-13T00:38:34Z",
        "body": "  - **Description:** Add `TrainableLLM` for those LLM support fine-tuning\r\n  - **Tag maintainer:** @hwchase17\r\n\r\nThis PR added a new ABC `TrainableLLM` and let `GradientLLM` implement it",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 109,
        "deletions": 36,
        "changed_files": 9,
        "created_at": "2023-10-12T16:48:05Z",
        "closed_at": null,
        "merged_at": null,
        "body": "For retry parser to work, the prompt needs to be available. I don't see how this is hooked up in the current implementation of  LLMChain. The LLMChain must the prompt with the generation to the appropriate output parser (I.e. the llm code must invoke parse_with_prompt). The real output parser could either use the base implementation of parse_with_prompt (i.e. simply call parse) or override it.\r\n\r\nWIP: Needs tests, unsure if schema changes affects consumers(don't think a lot of people are subclassing output_parser). If my assessment is wrong, I will drop the work",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-12T16:36:03Z",
        "closed_at": "2023-10-12T16:48:54Z",
        "merged_at": "2023-10-12T16:48:54Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-12T15:21:25Z",
        "closed_at": "2023-10-12T16:52:21Z",
        "merged_at": "2023-10-12T16:52:21Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-12T15:05:12Z",
        "closed_at": "2023-10-12T18:37:43Z",
        "merged_at": "2023-10-12T18:37:43Z",
        "body": "Add graph construction section to Neo4j provider docs",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 258,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-12T13:55:03Z",
        "closed_at": "2023-10-13T06:04:28Z",
        "merged_at": "2023-10-13T06:04:28Z",
        "body": "Motivation and Context\r\nAt present, the Baichuan Large Language Model is relatively popular and efficient in performance. Due to widespread market recognition, this model has been added to enhance the scalability of Langchain's ability to access the big language model, so as to facilitate application access and usage for interested users.\r\n\r\nSystem Info\r\nlangchain\uff1a 0.0.295\r\npython\uff1a3.8.3\r\nIDE\uff1avs code\r\n\r\nDescription\r\nAdd the following files:\r\n\r\n1. Add baichuan_baichuaninc_endpoint.py in the libs/langchain/langchain/chat_models\r\n2. Modify the __init__.py file,which is located in the libs/langchain/langchain/chat_models/__init__.py\uff1a\r\n    a. Add \"from langchain.chat_models.baichuan_baichuaninc_endpoint import BaichuanChatEndpoint\"\r\n    b. Add \"BaichuanChatEndpoint\" In the file's __ All__  method\r\n\r\nYour contribution\r\nI am willing to help implement this feature and submit a PR, but I would appreciate guidance from the maintainers or community to ensure the changes are made correctly and in line with the project's standards and practices.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-12T12:59:46Z",
        "closed_at": "2023-10-12T14:41:19Z",
        "merged_at": "2023-10-12T14:41:19Z",
        "body": "fixed minor typos;\r\nthe your > your\r\non > upon",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-12T12:38:55Z",
        "closed_at": "2023-10-12T14:17:10Z",
        "merged_at": "2023-10-12T14:17:10Z",
        "body": "funtion -> function",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2023-10-12T12:36:37Z",
        "closed_at": "2023-10-12T14:09:21Z",
        "merged_at": "2023-10-12T14:09:21Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-12T12:35:58Z",
        "closed_at": "2023-10-12T14:17:23Z",
        "merged_at": "2023-10-12T14:17:23Z",
        "body": "herarchy -> hierarchy",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-12T12:31:31Z",
        "closed_at": "2023-10-12T14:16:52Z",
        "merged_at": "2023-10-12T14:16:52Z",
        "body": "neccessary -> necessary",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-12T12:30:38Z",
        "closed_at": "2023-10-12T14:16:17Z",
        "merged_at": "2023-10-12T14:16:17Z",
        "body": "This PR has a number of typos correction. I kindly request the repo maintainers to review this PR and merge it. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-12T12:28:43Z",
        "closed_at": "2023-10-12T14:16:35Z",
        "merged_at": "2023-10-12T14:16:35Z",
        "body": "implemet -> implement",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 420,
        "deletions": 41,
        "changed_files": 7,
        "created_at": "2023-10-12T11:54:02Z",
        "closed_at": "2023-10-17T01:59:45Z",
        "merged_at": "2023-10-17T01:59:45Z",
        "body": "**Description**\r\n\r\n- Added the `SingleStoreDBChatMessageHistory` class that inherits `BaseChatMessageHistory` and allows to use of a SingleStoreDB database as a storage for chat message history.\r\n- Added integration test to check that everything works (requires `singlestoredb` to be installed)\r\n- Added notebook with usage example\r\n- Removed custom retriever for SingleStoreDB vector store (as it is useless)\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 534,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2023-10-12T11:19:38Z",
        "closed_at": "2023-10-17T03:30:08Z",
        "merged_at": "2023-10-17T03:30:08Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n  - **Description:** Introducing an ability to work with the [YandexGPT](https://cloud.yandex.com/en/services/yandexgpt) language model.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-12T11:14:25Z",
        "closed_at": "2023-10-12T13:13:59Z",
        "merged_at": "2023-10-12T13:13:59Z",
        "body": "Should delegate to parse_result, not to aparse, as parse_result is a method that some output parsers override\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-12T01:32:21Z",
        "closed_at": "2023-10-12T01:41:21Z",
        "merged_at": "2023-10-12T01:41:21Z",
        "body": "  - **Description:** fix docstring for clickhouse, \n  - **Issue:** N/A,\n  - **Dependencies:** none,\n  - **Tag maintainer:** N/A,\n  - **Twitter handle:** \n\n\n<!-- Thank you for contributing to LangChain!\n\nReplace this entire comment with:\n  - **Description:** a description of the change, \n  - **Issue:** the issue # it fixes (if applicable),\n  - **Dependencies:** any dependencies required for this change,\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\n\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\n\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \nhttps://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md\n\nIf you're adding a new integration, please include:\n  1. a test for the integration, preferably unit tests that do not rely on network access,\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\n\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\n -->\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-12T01:29:30Z",
        "closed_at": null,
        "merged_at": null,
        "body": "1. Remove single quotation marks from the string, because qwen may return a string within single quotation marks.\r\n2. Make the splition more robust, because qwen may return a list without blank after comma.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 252,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-12T01:03:07Z",
        "closed_at": "2023-10-12T01:03:13Z",
        "merged_at": "2023-10-12T01:03:13Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-11T23:33:33Z",
        "closed_at": "2023-10-11T23:40:23Z",
        "merged_at": "2023-10-11T23:40:23Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-10-11T23:25:39Z",
        "closed_at": "2023-10-12T00:05:42Z",
        "merged_at": "2023-10-12T00:05:42Z",
        "body": "  - **Description:** make the error messages consistent in chains/loading.py\r\n  - **Dependencies:** None",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 100,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-11T22:36:23Z",
        "closed_at": "2023-10-12T18:23:44Z",
        "merged_at": null,
        "body": "  - **Description:** \r\n     - Add GetByID strategy to allow retrieving exact documents when needed\r\n\r\n     - Update ElasticsearchStore to allow loading data from an index that does not follow the Langchain index structure by \r\n        remapping them.\r\n\r\n     - Fix store to return None for page_content when the field is missing, preventing hardfails if a specific document is \r\n       malformed.\r\n\r\n  - **Dependencies:** None\r\n  \r\n  - **Twitter handle:** Void",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 363,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-11T22:05:58Z",
        "closed_at": "2023-10-15T15:54:10Z",
        "merged_at": "2023-10-15T15:54:10Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2023-10-11T22:03:50Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** This PR proposes a simple implementation to add support for the Open AI `function_call` parameter and modifies the `with_function` for the `plan` method of the `ChatOpenAI`class accordingly.\r\n  - **Issue:** Right now, there is no way to force the model to generate a function call as enabled by the Open AI API.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-11T21:27:53Z",
        "closed_at": "2023-10-12T01:33:25Z",
        "merged_at": "2023-10-12T01:33:25Z",
        "body": "Add `type` to agent actions.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2023-10-11T21:27:11Z",
        "closed_at": "2023-10-17T04:05:08Z",
        "merged_at": "2023-10-17T04:05:08Z",
        "body": "the updated value was:\r\n` Criteria.MISOGYNY: \"Is the submission misogynistic? If so, respond Y.\" `\r\nThe \" If so, respond Y.\" should not be here. This sub-string is not presented in any other criteria and should not be presented here.\r\nI also added a synonym to \"misogynistic\" as it done in many other criteria.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-11T20:51:23Z",
        "closed_at": "2023-10-11T21:13:49Z",
        "merged_at": "2023-10-11T21:13:49Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-11T20:49:24Z",
        "closed_at": null,
        "merged_at": null,
        "body": "\r\nReplace this entire comment with:\r\n  - **Description:** `include_df_in_prompt` does now also work with `False` instade of `None` \r\n  - **Issue:**   #11677\r\n  - **Dependencies:** None\r\n  - **Tag maintainer:**\r\n  - **Twitter handle:** \r\n  \r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-11T20:33:31Z",
        "closed_at": "2023-10-11T21:02:12Z",
        "merged_at": "2023-10-11T21:02:12Z",
        "body": "Fixed title display ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-11T19:43:46Z",
        "closed_at": "2023-10-11T20:11:24Z",
        "merged_at": "2023-10-11T20:11:24Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 217,
        "deletions": 1,
        "changed_files": 5,
        "created_at": "2023-10-11T19:34:10Z",
        "closed_at": null,
        "merged_at": null,
        "body": "\r\n  - **Description:** Add COBOL parser and splitter\r\n  - **Issue:** n/a\r\n  - **Dependencies:** n/a\r\n  - **Tag maintainer:** @baskaryan \r\n  - **Twitter handle:** erhartford\r\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-11T19:22:51Z",
        "closed_at": "2023-10-11T20:37:04Z",
        "merged_at": "2023-10-11T20:37:04Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 41,
        "changed_files": 2,
        "created_at": "2023-10-11T17:51:43Z",
        "closed_at": "2023-10-11T20:02:03Z",
        "merged_at": "2023-10-11T20:02:03Z",
        "body": "* Should use non chunked messages for Invoke/Batch\n* After this PR, stream output type is not represented, do we want to use the union?\n\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-11T16:54:32Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** The WebBaseLoader has some problems when it came to handling page content properly. These issues ranged from unwanted or missing spaces, to unwanted characters like dots, multiple newlines, and even the addition of header, footer, ads, and other unwanted data in the page content. It was a roadblock that needed a solution. I made changes to extract the page_content using another python package named as trafilatura, which handles all the issues I described earlier. The BeautifulSoup package is still used for metadata extraction, just the text part is extracted using trafilatura.,\r\n  - **Dependencies:** trafilatura,\r\n  - **Tag maintainer:** @baskaryan , @eyurtsev , @hwchase17 ,\r\n  - **Twitter handle:** abrehmaaan",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-11T15:40:24Z",
        "closed_at": "2023-10-11T20:01:19Z",
        "merged_at": "2023-10-11T20:01:18Z",
        "body": "enviroment -> environment\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 570,
        "deletions": 2,
        "changed_files": 6,
        "created_at": "2023-10-11T13:42:41Z",
        "closed_at": null,
        "merged_at": null,
        "body": "## Description\r\n\r\nThis PR adds support for a lakeFS document loader. \r\n[lakeFS](https://lakefs.io/) provides version control over the data lake, and uses Git-like semantics to create and access those versions.\r\n\r\n---\r\n\r\n@hwchase17,\r\n  - **Twitter handle:** JonLaRose\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 244,
        "deletions": 237,
        "changed_files": 136,
        "created_at": "2023-10-11T13:34:14Z",
        "closed_at": "2023-10-12T15:44:03Z",
        "merged_at": "2023-10-12T15:44:03Z",
        "body": null,
        "comments": 4
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2023-10-11T13:27:23Z",
        "closed_at": "2023-10-11T13:45:32Z",
        "merged_at": "2023-10-11T13:45:32Z",
        "body": "\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 86,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-11T12:51:37Z",
        "closed_at": "2023-10-11T22:28:09Z",
        "merged_at": "2023-10-11T22:28:09Z",
        "body": "  - **Description:** Add SQLAlchemyMd5Cache implementation, \r\n  - **Issue:** the issue # #11655,\r\n  - **Dependencies:** no deps,\r\n  - **Tag maintainer:** @markowanga ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1015,
        "deletions": 9,
        "changed_files": 4,
        "created_at": "2023-10-11T11:44:04Z",
        "closed_at": "2023-10-11T22:38:08Z",
        "merged_at": "2023-10-11T22:38:08Z",
        "body": "Added demo for QA system with anonymization. It will be part of LangChain's privacy webinar.\r\n\r\n@hwchase17 @baskaryan @nfcampos \r\n\r\nTwitter handle: @MaksOpp",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-11T09:43:45Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Updated comments for better understanding of the search mechanism.\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 823,
        "deletions": 114,
        "changed_files": 1,
        "created_at": "2023-10-11T04:59:12Z",
        "closed_at": "2023-10-11T05:11:06Z",
        "merged_at": "2023-10-11T05:11:06Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 275,
        "deletions": 38,
        "changed_files": 4,
        "created_at": "2023-10-11T04:58:52Z",
        "closed_at": "2023-10-11T05:11:32Z",
        "merged_at": "2023-10-11T05:11:32Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 154,
        "deletions": 13,
        "changed_files": 23,
        "created_at": "2023-10-11T01:05:41Z",
        "closed_at": "2023-10-11T02:56:47Z",
        "merged_at": "2023-10-11T02:56:47Z",
        "body": "Added missed docstrings. Some reformatting.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-11T00:34:38Z",
        "closed_at": "2023-10-11T02:56:22Z",
        "merged_at": "2023-10-11T02:56:22Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1181,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-11T00:32:02Z",
        "closed_at": "2023-10-11T00:37:23Z",
        "merged_at": "2023-10-11T00:37:23Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 522,
        "deletions": 2126,
        "changed_files": 98,
        "created_at": "2023-10-10T23:18:22Z",
        "closed_at": "2023-10-11T19:27:14Z",
        "merged_at": "2023-10-11T19:27:13Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 118,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2023-10-10T22:57:50Z",
        "closed_at": "2023-10-12T15:42:33Z",
        "merged_at": "2023-10-12T15:42:33Z",
        "body": "Allows MMR functionality only for the case where we have access to the embedding function. Also allows for users to request for fields from elasticsearch store. These are added to the document metadata.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1265,
        "deletions": 4,
        "changed_files": 6,
        "created_at": "2023-10-10T22:49:07Z",
        "closed_at": "2023-10-11T20:56:46Z",
        "merged_at": "2023-10-11T20:56:46Z",
        "body": "This PR adds support for the Azure Cosmos DB MongoDB vCore Vector Store\r\n\r\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/\r\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search\r\n\r\nSummary:\r\n  - **Description:** added vector store integration for  Azure Cosmos DB MongoDB vCore Vector Store, \r\n  - **Issue:** the issue # it fixes #11627,\r\n  - **Dependencies:** pymongo dependency,\r\n  - **Tag maintainer:** @hwchase17,\r\n  - **Twitter handle:** @izzyacademy",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2023-10-10T22:08:15Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Currently the `embed_documents` (and async version) ignore the `chunk_size` param.\r\n\r\nUpdate passes it along to the relevant function.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-10T21:22:19Z",
        "closed_at": "2023-10-11T03:29:25Z",
        "merged_at": "2023-10-11T03:29:25Z",
        "body": "  - **Description:** Assigning the custom_llm_provider to the default params function so that it will be passed to the  litellm\r\n  - **Issue:** Even though the custom_llm_provider argument is being defined it's not being assigned anywhere in the code and hence its not being passed to litellm, therefore any litellm call which uses the custom_llm_provider as required parameter is being failed. This parameter is mainly used by litellm when we are doing inference via Custom API server. https://docs.litellm.ai/docs/providers/custom_openai_proxy\r\n  - **Dependencies:** No dependencies are required\r\n\r\n@krrishdholakia , @baskaryan \r\n  ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-10T19:57:58Z",
        "closed_at": "2023-10-10T19:58:04Z",
        "merged_at": "2023-10-10T19:58:04Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T19:37:50Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- **Description:** Uses `endpoint_url` if provided with a boto3 session. When running dynamodb locally, credentials are required even if invalid. With this change, it will be possible to pass a boto3 session with credentials and specify an endpoint_url\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-10T19:27:36Z",
        "closed_at": "2023-10-10T19:34:49Z",
        "merged_at": "2023-10-10T19:34:49Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 72,
        "deletions": 99,
        "changed_files": 1137,
        "created_at": "2023-10-10T19:20:54Z",
        "closed_at": "2023-10-10T19:55:19Z",
        "merged_at": "2023-10-10T19:55:19Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 63,
        "deletions": 619,
        "changed_files": 12,
        "created_at": "2023-10-10T18:42:52Z",
        "closed_at": "2023-10-10T18:54:09Z",
        "merged_at": "2023-10-10T18:54:09Z",
        "body": "Deprecate LLMBash and related bash utilities\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T16:43:40Z",
        "closed_at": "2023-10-11T03:32:45Z",
        "merged_at": "2023-10-11T03:32:45Z",
        "body": "\r\n**Description:** I noticed the metadata returned by the url_selenium loader was missing several values included by the web_base loader. (The former returned `{source: ...}`, the latter returned `{source: ..., title: ..., description: ..., language: ...}`.) This change fixes it so both loaders return all 4 key value pairs.\r\n\r\nFiles have been properly formatted and all tests are passing. Note, however, that I am not much of a python expert, so that whole \"Adding the imports inside the code so that tests pass\" thing seems weird to me. Please LMK if I did anything wrong.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 301,
        "changed_files": 4,
        "created_at": "2023-10-10T15:41:48Z",
        "closed_at": "2023-10-10T16:33:51Z",
        "merged_at": "2023-10-10T16:33:51Z",
        "body": "Deprecate LLMSymbolicMath from langchain core package.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 45,
        "changed_files": 2,
        "created_at": "2023-10-10T15:28:29Z",
        "closed_at": "2023-10-10T17:11:46Z",
        "merged_at": "2023-10-10T17:11:46Z",
        "body": "Update docs in lieu of:\n\nhttps://github.com/langchain-ai/langchain/discussions/11352\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-10T15:12:14Z",
        "closed_at": "2023-10-10T15:17:41Z",
        "merged_at": "2023-10-10T15:17:41Z",
        "body": "Add version to langchain experimental\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 231,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-10T15:07:41Z",
        "closed_at": "2023-10-10T15:08:05Z",
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T14:55:18Z",
        "closed_at": "2023-10-10T14:55:26Z",
        "merged_at": "2023-10-10T14:55:26Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-10T14:44:46Z",
        "closed_at": "2023-10-10T17:22:40Z",
        "merged_at": "2023-10-10T17:22:40Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n\r\nThere is some invalid link in open ai platform [docs](https://python.langchain.com/docs/integrations/platforms/openai).\r\nSo i fixed it to valid links.\r\n- `/docs/integrations/chat_models/openai` -> `/docs/integrations/chat/openai`\r\n- `/docs/integrations/chat_models/azure_openai` -> `/docs/integrations/chat/azure_chat_openai`\r\n\r\nThanks! \u263a\ufe0f\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 339,
        "deletions": 44,
        "changed_files": 2,
        "created_at": "2023-10-10T14:40:23Z",
        "closed_at": "2023-10-11T21:00:55Z",
        "merged_at": "2023-10-11T21:00:55Z",
        "body": "**Description:** This PR adds support for ChatOpenAI models in the Infino callback handler. In particular, this PR implements `on_chat_model_start` callback, so that ChatOpenAI models are supported. With this change, Infino callback handler can be used to track latency, errors, and prompt tokens for ChatOpenAI models too (in addition to the support for OpenAI and other non-chat models it has today). The existing example notebook is updated to show how to use this integration as well. cc/ @naman-modi @savannahar68\r\n\r\n**Issue:** https://github.com/langchain-ai/langchain/issues/11607 \r\n\r\n**Dependencies:** None\r\n\r\n**Tag maintainer:** @hwchase17 \r\n\r\n**Twitter handle:** [@vkakade](https://twitter.com/vkakade)\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 533,
        "deletions": 9,
        "changed_files": 9,
        "created_at": "2023-10-10T14:01:58Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:** \r\nAdd baidu cloud vector search in vectorstore\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T13:50:17Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Due to the possibility of external inputs including UUIDs, there may be additional values in **kwargs, while Weaviate's `__init__` method does not support passing extra **kwarg parameters.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 87,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2023-10-10T12:55:57Z",
        "closed_at": "2023-10-10T13:50:19Z",
        "merged_at": "2023-10-10T13:50:19Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T12:55:40Z",
        "closed_at": "2023-10-10T17:27:28Z",
        "merged_at": "2023-10-10T17:27:28Z",
        "body": "<!--\r\n\r\n  - **Description:** azureml_chat_endpoint code exemple now takes endpoint_url and endpoint_api_key parameter into consideration,\r\n  - **Issue:** None),\r\n  - **Dependencies:** None,\r\n  - **Tag maintainer:** None,\r\n  - **Twitter handle:** @ElliotAlladaye\r\n\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 142,
        "deletions": 13,
        "changed_files": 5,
        "created_at": "2023-10-10T12:34:34Z",
        "closed_at": "2023-10-10T21:17:22Z",
        "merged_at": "2023-10-10T21:17:22Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T11:34:32Z",
        "closed_at": null,
        "merged_at": null,
        "body": "The documents returned in any similarity search function doesnt returns the id of the document. This id can later be use to update the page_content or the metadata of the stored document in the vector store.\r\n\r\n@hwchase17 \r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2023-10-10T10:26:11Z",
        "closed_at": null,
        "merged_at": null,
        "body": "### Feature request\r\n\r\nAdd optional multithreading support for `TextSplitter`, e.g for the loop in `TextSplitter.create_documents`:\r\n\r\nhttps://github.com/langchain-ai/langchain/blob/e2a9072b806b1a45b0e4c107b30dddd0f67a453f/libs/langchain/langchain/text_splitter.py#L138-L153\r\n\r\n\r\nQuestion: Is there anything opposing this idea / preventing it from a  technical perspective?\r\n\r\n### Motivation\r\n\r\nText splitting can take up significant time and resources if a custom length function is used to measure chunk length (e.g. based on a huggingface tokenizer's encode method), especially for the `RecursiveCharacterTextSplitter`.\r\n\r\nTherefore we want to introduce multithreading support on a document level.\r\n\r\n### Your contribution\r\n\r\nFeature Request: https://github.com/langchain-ai/langchain/issues/11595\r\nPR: https://github.com/langchain-ai/langchain/pull/11598",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 55,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2023-10-10T10:23:40Z",
        "closed_at": "2023-10-11T21:50:42Z",
        "merged_at": "2023-10-11T21:50:42Z",
        "body": "  - **Description:** Add allow_list support in langchain experimental data-anonymizer package\r\n  - **Issue:** no\r\n  - **Dependencies:** no\r\n  - **Tag maintainer:** @hwchase17\r\n  - **Twitter handle:** \r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 141,
        "deletions": 104,
        "changed_files": 2,
        "created_at": "2023-10-10T10:05:42Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T09:18:47Z",
        "closed_at": "2023-10-11T21:05:53Z",
        "merged_at": "2023-10-11T21:05:53Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\nI am merely making some minor adjustments to the function documentation. I hope to provide a small assistance to LangChain.\r\n  - **Description:** Change the docs of JSONAgentOutputParser. It will be `JSON` better,\r\n  - **Issue:** no,\r\n  - **Dependencies:** no,\r\n  - **Tag maintainer:** @hwchase17,\r\n  - **Twitter handle:** Not worth mentioning.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 132,
        "deletions": 32,
        "changed_files": 3,
        "created_at": "2023-10-10T06:26:37Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** add openvino backend support by HuggingFace Optimum Intel, \r\n  - **Dependencies:** \u201coptimum[openvino]\u201d,",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T04:13:10Z",
        "closed_at": null,
        "merged_at": null,
        "body": "feat: Raise KeyError when 'prompt' key is missing in JSON response\r\n\r\nThis commit updates the error handling in the code to raise a KeyError when the 'prompt' key is not found in the JSON response. This change makes the code more explicit about the nature of the error, helping to improve clarity and debugging.\r\n\r\n@baskaryan, @eyurtsev.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-10T02:20:44Z",
        "closed_at": "2023-10-10T02:21:56Z",
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 152,
        "deletions": 343,
        "changed_files": 7,
        "created_at": "2023-10-10T02:13:02Z",
        "closed_at": "2023-10-11T19:06:42Z",
        "merged_at": "2023-10-11T19:06:42Z",
        "body": "Adds standard `type` field for all messages that will be serialized/validated by pydantic.\r\n\r\n* The presence of `type` makes it easier for developers consuming schemas to write client code to serialize/deserialize.\r\n* In LangServe `type` will be used for both validation and will appear in the generated openapi specs\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-10T00:34:13Z",
        "closed_at": "2023-10-10T06:26:35Z",
        "merged_at": "2023-10-10T06:26:35Z",
        "body": "**Description:** CohereRerank is missing `cohere_api_key` as a field and since extras are forbidden, it is not possible to pass-in the key.  The only way is to use an env variable named `COHERE_API_KEY`.\r\n\r\nFor example, if trying to create a compressor like this:\r\n```python\r\ncohere_api_key = \"......Cohere api key......\"\r\ncompressor = CohereRerank(cohere_api_key=cohere_api_key)\r\n```\r\nyou will get the following error:\r\n```\r\n  File \"/langchain/.venv/lib/python3.10/site-packages/pydantic/v1/main.py\", line 341, in __init__\r\n    raise validation_error\r\npydantic.v1.error_wrappers.ValidationError: 1 validation error for CohereRerank\r\ncohere_api_key\r\n  extra fields not permitted (type=value_error.extra)\r\n```",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1558,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-10T00:03:41Z",
        "closed_at": "2023-10-13T15:45:55Z",
        "merged_at": "2023-10-13T15:45:55Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 76,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-09T22:48:07Z",
        "closed_at": "2023-10-12T19:17:44Z",
        "merged_at": "2023-10-12T19:17:44Z",
        "body": "**Description:** Update Indexing API docs to specify vectorstores that are compatible with the Indexing API. I add a unit test to remind developers to update the documentation whenever they add or change a vectorstore in a way that affects compatibility. For the unit test I repurposed existing code from [here](https://github.com/langchain-ai/langchain/blob/v0.0.311/libs/langchain/langchain/indexes/_api.py#L245-L257).\r\n\r\nThis is my first PR to an open source project. This is a trivially simple PR whose main purpose is to make me more comfortable submitting Langchain PRs. If this PR goes through I plan to submit PRs with more substantive changes in the near future. \r\n\r\n**Issue:** Resolves [10482](https://github.com/langchain-ai/langchain/discussions/10482).\r\n\r\n**Dependencies:** No new dependencies.\r\n\r\n**Twitter handle:** None.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 773,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2023-10-09T21:42:59Z",
        "closed_at": "2023-10-10T17:20:45Z",
        "merged_at": "2023-10-10T17:20:45Z",
        "body": "  - **Description:** This PR introduces a new LLM and Retriever API to https://arcee.ai for the python client\r\n  - **Issue:** implements the integrations as requested in #11578 ,\r\n  - **Dependencies:** no dependencies are required,\r\n  - **Tag maintainer:** @hwchase17\r\n  - **Twitter handle:** shwooobham \r\n\r\n\r\n**\u2705 `make format`, `make lint` and `make test` runs locally.**\r\n```shell\r\n=========== 1245 passed, 277 skipped, 20 warnings in 16.26s ===========\r\n./scripts/check_pydantic.sh .\r\n./scripts/check_imports.sh\r\npoetry run ruff .\r\n[ \".\" = \"\" ] || poetry run black . --check\r\nAll done! \u2728 \ud83c\udf70 \u2728\r\n1818 files would be left unchanged.\r\n[ \".\" = \"\" ] || poetry run mypy .\r\nSuccess: no issues found in 1815 source files\r\n[ \".\" = \"\" ] || poetry run black .\r\nAll done! \u2728 \ud83c\udf70 \u2728\r\n1818 files left unchanged.\r\n[ \".\" = \"\" ] || poetry run ruff --select I --fix .\r\npoetry run codespell --toml pyproject.toml\r\npoetry run codespell --toml pyproject.toml -w\r\n```\r\n\r\n\r\n**Contributions**\r\n1. Arcee (langchain/llms), ArceeRetriever (langchain/retrievers), ArceeWrapper (langchain/utilities)\r\n2. docs for Arcee (llms/arcee.py) and ArceeRetriever(retrievers/arcee.py)\r\n3.\r\n\r\ncc: @jacobsolawetz @ben-epstein\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 199,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-09T20:54:15Z",
        "closed_at": "2023-10-09T20:54:27Z",
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-09T20:49:30Z",
        "closed_at": "2023-10-09T21:56:45Z",
        "merged_at": "2023-10-09T21:56:45Z",
        "body": "#### Description\r\nThis PR adds the option to specify additional metadata columns in the CSVLoader beyond just `Source`. \r\n\r\nThe current CSV loader includes all columns in `page_content` and if we want to have columns specified for `page_content` and `metadata` we have to do something like the below.:\r\n```\r\ncsv = pd.read_csv(\r\n        \"path_to_csv\"\r\n    ).to_dict(\"records\")\r\n\r\ndocuments = [\r\n        Document(\r\n            page_content=doc[\"content\"],\r\n            metadata={\r\n                \"last_modified_by\": doc[\"last_modified_by\"],\r\n                \"point_of_contact\": doc[\"point_of_contact\"],\r\n            }\r\n        ) for doc in csv\r\n    ]\r\n```\r\n#### Usage\r\nExample Usage:\r\n```\r\ncsv_test  =  CSVLoader(\r\n      file_path=\"path_to_csv\", \r\n      metadata_columns=[\"last_modified_by\", \"point_of_contact\"]\r\n )\r\n```\r\nExample CSV:\r\n```\r\ncontent, last_modified_by, point_of_contact\r\n\"hello world\", \"Person A\", \"Person B\"\r\n```\r\n\r\nExample Result:\r\n```\r\nDocument {\r\n page_content: \"hello world\"\r\n metadata: {\r\n row: '0',\r\n source: 'path_to_csv',\r\n last_modified_by: 'Person A',\r\n point_of_contact: 'Person B',\r\n }\r\n```\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 159,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2023-10-09T19:25:32Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** Adding a notebook for Press Release data from Kay.ai, as discussed offline\r\n  - **Tag maintainer:** @baskaryan @hwchase17 \r\n  - **Twitter handle:** https://twitter.com/kaydotai https://twitter.com/vishalrohra_\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2023-10-09T19:09:09Z",
        "closed_at": "2023-10-09T20:30:17Z",
        "merged_at": "2023-10-09T20:30:17Z",
        "body": "Code was assuming that `git` and `poetry` exist. In addition, it was not ignoring pycache files that get generated during run time",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-09T18:34:36Z",
        "closed_at": "2023-10-09T20:27:03Z",
        "merged_at": "2023-10-09T20:27:03Z",
        "body": "**Description**\r\nThis PR adds an additional Example to the Redis integration documentation. [The example](https://learn.microsoft.com/azure/azure-cache-for-redis/cache-tutorial-vector-similarity) is a step-by-step walkthrough of using Azure Cache for Redis and Azure OpenAI for vector similarity search, using LangChain extensively throughout. \r\n\r\n**Issue**\r\nNothing specific, just adding an additional example.\r\n\r\n**Dependencies**\r\nNone.\r\n\r\n**Tag Maintainer**\r\nTagging @hwchase17 :)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 239,
        "deletions": 99,
        "changed_files": 2,
        "created_at": "2023-10-09T18:27:43Z",
        "closed_at": "2023-10-12T15:41:26Z",
        "merged_at": "2023-10-12T15:41:25Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n\r\n **Description:** Modify Anyscale integration to work with [Anyscale Endpoint](https://docs.endpoints.anyscale.com/)\r\nand it supports invoke, async invoke, stream and async invoke features\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3953,
        "deletions": 0,
        "changed_files": 14,
        "created_at": "2023-10-09T18:13:44Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- [ ] deprecation notice in main lib (how do we do those?)\r\n- [ ] add CI jobs\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1084,
        "deletions": 64,
        "changed_files": 12,
        "created_at": "2023-10-09T18:11:58Z",
        "closed_at": "2023-10-09T21:03:00Z",
        "merged_at": "2023-10-09T21:03:00Z",
        "body": "**Description**:\r\n\r\n- Added Momento Vector Index (MVI) as a vector store provider. This includes an implementation with docstrings, integration tests, a notebook, and documentation on the docs pages.\r\n- Updated the Momento dependency in pyproject.toml and the lock file to enable access to MVI.\r\n- Refactored the Momento cache and chat history session store to prefer using \"MOMENTO_API_KEY\" over \"MOMENTO_AUTH_TOKEN\" for consistency with MVI. This change is backwards compatible with the previous \"auth_token\" variable usage. Updated the code and tests accordingly.\r\n\r\n**Dependencies**:\r\n\r\n- Updated Momento dependency in pyproject.toml.\r\n\r\n**Testing**:\r\n\r\n- Run the integration tests with a Momento API key. Get one at the [Momento Console](https://console.gomomento.com) for free. MVI is available in AWS us-west-2 with a superuser key.\r\n- `MOMENTO_API_KEY=<your key> poetry run pytest tests/integration_tests/vectorstores/test_momento_vector_index.py`\r\n\r\n**Tag maintainer:**\r\n\r\n@eyurtsev\r\n\r\n**Twitter handle**:\r\n\r\nPlease mention @momentohq for this addition to langchain. With the integration of Momento Vector Index, Momento caching, and session store, Momento provides serverless support for the core langchain data needs.\r\n\r\nAlso mention @mlonml for the integration.\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2023-10-09T18:03:56Z",
        "closed_at": "2023-10-09T21:56:55Z",
        "merged_at": "2023-10-09T21:56:55Z",
        "body": "LangChain relies on NumPy to compute cosine distances, which becomes a bottleneck with the growing dimensionality and number of embeddings. To avoid this bottleneck, in our libraries at [Unum](https://github.com/unum-cloud), we have created a specialized package - [SimSIMD](https://github.com/ashvardanian/simsimd), that knows how to use newer hardware capabilities. Compared to SciPy and NumPy, it reaches 3x-200x performance for various data types. Since publication, several LangChain users have asked me if I can integrate it into LangChain to accelerate their workflows, so here I am \ud83e\udd17 \r\n\r\n## Benchmarking\r\n\r\nTo conduct benchmarks locally, run this in your Jupyter:\r\n\r\n```py\r\nimport numpy as np\r\nimport scipy as sp\r\nimport simsimd as simd\r\nimport timeit as tt\r\n\r\ndef cosine_similarity_np(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\r\n    X_norm = np.linalg.norm(X, axis=1)\r\n    Y_norm = np.linalg.norm(Y, axis=1)\r\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\r\n        similarity = np.dot(X, Y.T) / np.outer(X_norm, Y_norm)\r\n    similarity[np.isnan(similarity) | np.isinf(similarity)] = 0.0\r\n    return similarity\r\n\r\ndef cosine_similarity_sp(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\r\n    return 1 - sp.spatial.distance.cdist(X, Y, metric='cosine')\r\n\r\ndef cosine_similarity_simd(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\r\n    return 1 - simd.cdist(X, Y, metric='cosine')\r\n\r\nX = np.random.randn(1, 1536).astype(np.float32)\r\nY = np.random.randn(1, 1536).astype(np.float32)\r\nrepeat = 1000\r\n\r\nprint(\"NumPy: {:,.0f} ops/s, SciPy: {:,.0f} ops/s, SimSIMD: {:,.0f} ops/s\".format(\r\n    repeat / tt.timeit(lambda: cosine_similarity_np(X, Y), number=repeat),\r\n    repeat / tt.timeit(lambda: cosine_similarity_sp(X, Y), number=repeat),\r\n    repeat / tt.timeit(lambda: cosine_similarity_simd(X, Y), number=repeat),\r\n))\r\n```\r\n\r\n## Results\r\n\r\nI ran this on an M2 Pro Macbook for various data types and different number of rows in `X` and reformatted the results as a table for readability:\r\n\r\n| Data Type | NumPy | SciPy | SimSIMD |\r\n| :--- | ---: | ---: | ---: |\r\n| `f32, 1` | 59,114 ops/s | 80,330 ops/s | 475,351 ops/s |\r\n| `f16, 1` | 32,880 ops/s | 82,420 ops/s | 650,177 ops/s |\r\n| `i8, 1` | 47,916 ops/s | 115,084 ops/s | 866,958 ops/s |\r\n| `f32, 10` | 40,135 ops/s | 24,305 ops/s | 185,373 ops/s |\r\n| `f16, 10` | 7,041 ops/s | 17,596 ops/s | 192,058 ops/s |\r\n| `f16, 10` | 21,989 ops/s | 25,064 ops/s | 619,131 ops/s |\r\n| `f32, 100` | 3,536 ops/s | 3,094 ops/s | 24,206 ops/s |\r\n| `f16, 100` | 900 ops/s | 2,014 ops/s | 23,364 ops/s |\r\n| `i8, 100` | 5,510 ops/s | 3,214 ops/s | 143,922 ops/s |\r\n\r\nIt's important to note that SimSIMD will underperform if both matrices are huge.\r\nThat, however, seems to be an uncommon usage pattern for LangChain users.\r\nYou can find a much more detailed performance report for different hardware models here:\r\n\r\n- [Apple M2 Pro](https://ashvardanian.com/posts/simsimd-faster-scipy/#appendix-1-performance-on-apple-m2-pro).\r\n- [4th Gen Intel Xeon Platinum](https://ashvardanian.com/posts/simsimd-faster-scipy/#appendix-2-performance-on-4th-gen-intel-xeon-platinum-8480).\r\n- [AWS Graviton 3](https://ashvardanian.com/posts/simsimd-faster-scipy/#appendix-3-performance-on-aws-graviton-3).\r\n  \r\n## Additional Notes\r\n\r\n1. Previous version used `X = np.array(X)`, to repackage lists of lists. It's an anti-pattern, as it will use double-precision floating-point numbers, which are slow on both CPUs and GPUs. I have replaced it with `X = np.array(X, dtype=np.float32)`, but a more selective approach should be discussed.\r\n2. In numerical computations, it's recommended to explicitly define tolerance levels, which were previously avoided in `np.allclose(expected, actual)` calls. For now, I've set absolute tolerance to distance computation errors as 0.01: `np.allclose(expected, actual, atol=1e-2)`.\r\n\r\n---\r\n\r\n  - **Dependencies:** adds `simsimd` dependency\r\n  - **Tag maintainer:** @hwchase17\r\n  - **Twitter handle:** @ashvardanian ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 117,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2023-10-09T17:49:36Z",
        "closed_at": "2023-10-12T14:10:16Z",
        "merged_at": "2023-10-12T14:10:16Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 214,
        "deletions": 175,
        "changed_files": 1,
        "created_at": "2023-10-09T17:28:49Z",
        "closed_at": "2023-10-09T20:26:36Z",
        "merged_at": "2023-10-09T20:26:36Z",
        "body": "Wraps every callback handler method in error handlers to avoid breaking users' programs when an error occurs inside the handler. \r\n\r\nThanks @valdo99 for the suggestion \ud83d\ude42 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-09T16:50:32Z",
        "closed_at": "2023-10-09T16:58:04Z",
        "merged_at": "2023-10-09T16:58:04Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2023-10-09T16:47:29Z",
        "closed_at": "2023-10-12T15:41:52Z",
        "merged_at": "2023-10-12T15:41:52Z",
        "body": "**Description**\r\n\r\nThis PR implements the usage of the correct tokenizer in Bedrock LLMs, if using anthropic models.\r\n\r\n**Issue:** #11560\r\n\r\n**Dependencies:** optional dependency on `anthropic` python library.\r\n\r\n**Twitter handle:** jtolgyesi\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-09T15:49:56Z",
        "closed_at": "2023-10-09T18:11:05Z",
        "merged_at": "2023-10-09T18:11:05Z",
        "body": "@hwchase17 @baskaryan ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-09T15:39:58Z",
        "closed_at": "2023-10-09T18:10:46Z",
        "merged_at": "2023-10-09T18:10:46Z",
        "body": "https://microsoft.github.io/presidio/supported_entities/\r\n\r\n@baskaryan @hwchase17 ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 893,
        "deletions": 510,
        "changed_files": 5,
        "created_at": "2023-10-09T15:38:06Z",
        "closed_at": "2023-10-09T18:10:29Z",
        "merged_at": "2023-10-09T18:10:29Z",
        "body": "@baskaryan, @hwchase17\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-09T15:22:27Z",
        "closed_at": "2023-10-09T15:43:04Z",
        "merged_at": "2023-10-09T15:43:04Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-09T15:11:58Z",
        "closed_at": "2023-10-09T15:17:07Z",
        "merged_at": "2023-10-09T15:17:07Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-09T14:59:21Z",
        "closed_at": "2023-10-11T23:05:13Z",
        "merged_at": "2023-10-11T23:05:13Z",
        "body": "Replace this entire comment with:\r\n  - **Description:** In this modified version of the function, if the metadatas parameter is not None, the function includes the corresponding metadata in the JSON object for each text. This allows the metadata to be stored alongside the text's embedding in the vector store.\r\n  - \r\n  - **Issue:** #10924\r\n  - **Dependencies:** None\r\n  - **Tag maintainer:** @hwchase17\r\n@agola11\r\n  - **Twitter handle:** @MelliJoaco\r\n\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 58,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-09T14:40:07Z",
        "closed_at": "2023-10-09T20:02:16Z",
        "merged_at": "2023-10-09T20:02:16Z",
        "body": "Add in code documentation for a runnable passthrough\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 712,
        "deletions": 211,
        "changed_files": 15,
        "created_at": "2023-10-09T14:29:44Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Yield a \"stream reset\" marker before starting the next attempt\r\n\r\nOpen question: How to deal with this best in RunnableSequence/RunnableMap? The next steps in the sequence are probably not designed to handle the reset marker, should RunnableSequence retry all steps after \"current\" once it sees a retry marker?\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-09T13:59:28Z",
        "closed_at": "2023-10-09T20:02:30Z",
        "merged_at": "2023-10-09T20:02:30Z",
        "body": "Add in code documentation for langchain runnables module.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2023-10-09T13:04:02Z",
        "closed_at": "2023-10-11T23:26:56Z",
        "merged_at": "2023-10-11T23:26:56Z",
        "body": "This commit fixes the documentation about n-gram overlap that unrelated variables are declared.\r\n\r\nReplace this entire comment with:\r\n  - **Description:** Fix the documentation in https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/ngram_overlap. It's currently declaring unrelated variables, for example, `examples` local variable is declared twice and the first one is overwritten immediately.\r\n  - **Issue:** N/A\r\n  - **Dependencies:** N/A\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** @dosuken123\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-09T08:14:41Z",
        "closed_at": "2023-10-12T00:06:04Z",
        "merged_at": "2023-10-12T00:06:04Z",
        "body": "<!--\r\n  - **Description:** add 'language' to the reponse message in the Llama doc, \r\n  - **Issue:** None,\r\n  - **Dependencies:** None,\r\n  - **Tag maintainer:** None,\r\n  - **Twitter handle:** None\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-08T21:54:34Z",
        "closed_at": "2023-10-09T21:55:45Z",
        "merged_at": "2023-10-09T21:55:45Z",
        "body": "  - **Description:** Fixes the comments in the ConvoOutputParser. Because the \\\\\\\\ is escaping a single \\\\, they render something like:  `\"action_input\": string \\ The input to the action` in the prompt. Changing this to \\\\\\\\\\\\\\\\ lets it escape two slashes so that it renders a proper comment: `\"action_input\": string \\\\ The input to the action`\r\n  - **Issue:** N/A\r\n  - **Dependencies:** \r\n  - **Tag maintainer:** @hwchase17\r\n  - **Twitter handle:**",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2023-10-08T21:32:53Z",
        "closed_at": "2023-10-09T17:55:46Z",
        "merged_at": "2023-10-09T17:55:46Z",
        "body": "[The `duckduckgo-search` v3.9.2 was removed from PyPi](https://pypi.org/project/duckduckgo-search/#history). That breaks the build.\r\n\r\n  - **Description:** refreshes the Poetry dependency to v3.9.3\r\n  - **Tag maintainer:** @baskaryan\r\n  - **Twitter handle:** @ashvardanian ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-08T16:15:17Z",
        "closed_at": "2023-10-09T22:32:46Z",
        "merged_at": "2023-10-09T22:32:46Z",
        "body": "  - **Description:** Fixes minor typo for the query_sql_database_tool_description in the db toolkit\r\n  - **Issue:** N/A\r\n  - **Dependencies:** N/A\r\n  - **Tag maintainer:** @nfcampos \r\n  - **Twitter handle:** N/A",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-10-08T15:37:17Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:**\r\nCurrently, the example uses Pydantic 1 format and crashes with the following error:\r\n```\r\n    452 if isinstance(info, ValidatorDecoratorInfo):\r\n--> 453     res.validators[var_name] = Decorator.build(\r\n    454         model_dc, cls_var_name=var_name, shim=var_value.shim, info=info\r\n    455     )\r\n    456 elif isinstance(info, FieldValidatorDecoratorInfo):\r\n    457     res.field_validators[var_name] = Decorator.build(\r\n    458         model_dc, cls_var_name=var_name, shim=var_value.shim, info=info\r\n...\r\n     83         needs_values_kw = True\r\n\r\nPydanticUserError: The `field` and `config` parameters are not available in Pydantic V2, please use the `info` parameter instead.\r\n```\r\n\r\nAdditionally, it produces a warning:\r\n```\r\nPydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\r\n  @validator('setup')\r\n```\r\n------\r\nHere I'm updating it to use Pydantic2 syntax\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-08T15:35:10Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Replace this entire comment with:\r\n  - **Description:** [PromptTemplate with OutputParser](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/prompt_serialization#prompttemplate-with-outputparser) has an example with \"template\": `\"Given the following question and student answer, provide a correct answer and score the student answer.\\nQuestion: {question}\\nStudent Answer: {student_answer}\\nCorrect Answer:\"`, however, `\\n` is a control character therefore `load_prompt ` results in an error like `ERROR Invalid control character at: line 1 column 202 (char 202)`. This is expected behavior from the `json` package (See https://stackoverflow.com/questions/22394235/invalid-control-character-with-python-json-loads for more information). This PR removes these control characters. I've confirmed that the fixed example is working on Google Colab .\r\n  - **Issue:** Not found,\r\n  - **Dependencies:** Nope,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** @dosuken123\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 487,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2023-10-08T14:59:46Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** add a batch loader to better use loader on a list of data sources\r\n  - **Issue:**  #11509 ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 105,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-10-08T11:17:48Z",
        "closed_at": "2023-10-11T21:43:48Z",
        "merged_at": "2023-10-11T21:43:48Z",
        "body": "**Description:**\r\nAdd  BaiduCloud BOS document loader. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2023-10-08T07:11:48Z",
        "closed_at": "2023-10-09T22:40:27Z",
        "merged_at": "2023-10-09T22:40:27Z",
        "body": "**Description:**\r\nThis PR fix some code snippets that have raw `\\n`'s instead of actual line breaks.\r\n\r\n**Issue:**\r\nCurrently some snippets look like this:\r\n![image](https://github.com/langchain-ai/langchain/assets/18213435/355b4911-38e9-4ba4-8570-f928557b6c13)\r\n\r\nAffected pages:\r\n - https://python.langchain.com/docs/integrations/providers/predictionguard#example-usage\r\n - https://python.langchain.com/docs/modules/agents/how_to/custom_llm_agent#set-up-environment\r\n - https://python.langchain.com/docs/modules/chains/foundational/llm_chain#get-started\r\n - https://python.langchain.com/docs/integrations/providers/shaleprotocol#how-to\r\n\r\n**Tag maintainer:**\r\n@hwchase17 \r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2023-10-08T02:26:24Z",
        "closed_at": "2023-10-11T21:34:28Z",
        "merged_at": "2023-10-11T21:34:28Z",
        "body": "- **Description:** fixed a bug in pal-chain when it reports Python\r\n    code validation errors. When node.func does not have any ids, the\r\n    original code tried to print node.func.id in raising ValueError.\r\n- **Issue:** n/a,\r\n- **Dependencies:** no dependencies,\r\n- **Tag maintainer:** @hazzel-cn, @eyurtsev\r\n- **Twitter handle:** @lazyswamp",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 56,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-08T01:19:15Z",
        "closed_at": "2023-10-09T18:37:47Z",
        "merged_at": "2023-10-09T18:37:47Z",
        "body": "Add in code docs for Runnable Lambda\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2023-10-08T00:53:54Z",
        "closed_at": "2023-10-17T15:46:09Z",
        "merged_at": "2023-10-17T15:46:09Z",
        "body": "Need to look at preview whether this works.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 94,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2023-10-08T00:14:05Z",
        "closed_at": "2023-10-11T23:30:16Z",
        "merged_at": "2023-10-11T23:30:16Z",
        "body": "No relevant documents may be found for a given question. In some use cases, we could directly respond with a fixed message instead of doing an LLM call with an empty context. This PR exposes this as an option: response_if_no_docs_found.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 48,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2023-10-07T23:10:03Z",
        "closed_at": "2023-10-09T23:29:43Z",
        "merged_at": "2023-10-09T23:29:43Z",
        "body": "This PR provides add files method with LLMRails. Implemented here are:\r\n\r\ndocs/extras/integrations/vectorstores/llm-rails.ipynb",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 608,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2023-10-07T23:02:59Z",
        "closed_at": "2023-10-07T23:04:11Z",
        "merged_at": null,
        "body": "This PR provides add files method with LLMRails. Implemented here are:\r\n\r\ndocs/extras/integrations/vectorstores/llm-rails.ipynb",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 74,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-07T19:59:48Z",
        "closed_at": "2023-10-08T07:09:04Z",
        "merged_at": "2023-10-08T07:09:04Z",
        "body": "Add in code documentation for runnable.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 325,
        "deletions": 28,
        "changed_files": 4,
        "created_at": "2023-10-07T18:00:41Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** `PGVector` refactored to use connection pool.\r\n  - **Issue:** #11433,\r\n  - **Tag maintainer:** @hwchase17 @eyurtsev,\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 283,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2023-10-07T15:34:08Z",
        "closed_at": null,
        "merged_at": null,
        "body": "- **Description:** Implementing the Google Scholar Tool as requested in PR #11505. The tool will be using the [serpapi python package](https://serpapi.com/integrations/python#search-google-scholar). The main idea of the tool will be to return the results from a Google Scholar search given a query as an input to the tool.\r\n\r\n- **Tag maintainer:** @baskaryan, @eyurtsev, @hwchase17\r\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2023-10-07T14:59:09Z",
        "closed_at": "2023-10-09T20:45:11Z",
        "merged_at": null,
        "body": "#### Description\r\nThis PR adds the option to specify additional metadata columns in the CSVLoader beyond just `Source`. \r\n\r\nThe current CSV loader includes all columns in `page_content` and if we want to have columns specified for `page_content` and `metadata` we have to do something like the below.:\r\n```\r\ncsv = pd.read_csv(\r\n        \"path_to_csv\"\r\n    ).to_dict(\"records\")\r\n\r\ndocuments = [\r\n        Document(\r\n            page_content=doc[\"content\"],\r\n            metadata={\r\n                \"last_modified_by\": doc[\"last_modified_by\"],\r\n                \"point_of_contact\": doc[\"point_of_contact\"],\r\n            }\r\n        ) for doc in csv\r\n    ]\r\n```\r\n#### Usage\r\nExample Usage:\r\n```\r\ncsv_test  =  CSVLoader(\r\n      file_path=\"path_to_csv\", \r\n      metadata_columns=[\"last_modified_by\", \"point_of_contact\"]\r\n )\r\n```\r\nExample CSV:\r\n```\r\ncontent, last_modified_by, point_of_contact\r\n\"hello world\", \"Person A\", \"Person B\"\r\n```\r\n\r\nExample Result:\r\n```\r\nDocument {\r\n page_content: \"hello world\"\r\n metadata: {\r\n row: '0',\r\n source: 'path_to_csv',\r\n last_modified_by: 'Person A',\r\n point_of_contact: 'Person B',\r\n }\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 336,
        "deletions": 2,
        "changed_files": 5,
        "created_at": "2023-10-07T12:49:37Z",
        "closed_at": "2023-10-12T22:05:39Z",
        "merged_at": "2023-10-12T22:05:39Z",
        "body": " **Description:**\r\n\r\nAdd a document loader for the RSpace Electronic Lab Notebook (www.researchspace.com), so that scientific documents and research notes can be easily pulled into Langchain pipelines. \r\n\r\n**Issue**\r\n\r\nThis is an new contribution, rather than an issue fix.\r\n\r\n **Dependencies:** \r\n  \r\nThere are no new required dependencies.\r\n In order to use the loader, clients will need to install rspace_client SDK using `pip install rspace_client`\r\n\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-10-07T02:37:59Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Noticed and fixed a few typos in the SmartLLMChain default ideation and critique prompts",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 625,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2023-10-07T02:07:21Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Resolved: Revert \"Add ChatGLM for llm and chat_model by using ChatGLM API (#9797)\" #10805\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 316,
        "deletions": 127,
        "changed_files": 4,
        "created_at": "2023-10-06T22:37:28Z",
        "closed_at": "2023-10-09T15:10:52Z",
        "merged_at": "2023-10-09T15:10:52Z",
        "body": "updating query constructor and self query retriever to\r\n- make it easier to pass in examples\r\n- validate attributes used in query\r\n- remove invalid parts of query\r\n- make it easier to get + edit prompt\r\n- make query constructor a runnable\r\n- make self query retriever use as runnable",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2023-10-06T22:12:45Z",
        "closed_at": "2023-10-12T01:13:42Z",
        "merged_at": "2023-10-12T01:13:42Z",
        "body": "Prevents document loading from erroring out when an attachment is not found at the url.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 449,
        "deletions": 360,
        "changed_files": 1,
        "created_at": "2023-10-06T22:02:32Z",
        "closed_at": "2023-10-10T16:31:24Z",
        "merged_at": "2023-10-10T16:31:24Z",
        "body": "A regular update of dependents.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1335,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2023-10-06T21:56:00Z",
        "closed_at": null,
        "merged_at": null,
        "body": "This PR adds [Bigframes (BigQuery DataFrames)](https://cloud.google.com/python/docs/reference/bigframes/latest) integration to Langchain. BigQuery DataFrames provides a Pythonic DataFrame and machine learning (ML) API powered by the BigQuery engine. BigFrames supports manipulating data in the DataFrame to build LLM prompts, and sending DataFrame prompts to the LLM model using [text-bison model of the PaLM API](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text)\r\n\r\nUsing BigFramesChain, you can now batch prompts using DataFrames as input and output.\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2023-10-06T21:23:47Z",
        "closed_at": "2023-10-06T21:43:29Z",
        "merged_at": "2023-10-06T21:43:29Z",
        "body": "These attributes can be filled by an environment variable, but are not marked as a secret. Thus, when invoking serialisation, the values are not included in the output JSON.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-06T21:23:21Z",
        "closed_at": "2023-10-12T01:44:47Z",
        "merged_at": "2023-10-12T01:44:47Z",
        "body": "**Description:**\r\n\r\nMake the example extraction code on https://python.langchain.com/docs/use_cases/extraction work again by importing the langchain.pydantic_v1 lib instead of the v2.\r\n\r\n**Issue:**\r\n\r\nSolves issue https://github.com/langchain-ai/langchain/issues/11468\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2023-10-06T21:23:19Z",
        "closed_at": "2023-10-12T01:43:52Z",
        "merged_at": "2023-10-12T01:43:52Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-06T19:49:40Z",
        "closed_at": "2023-10-06T19:57:24Z",
        "merged_at": "2023-10-06T19:57:24Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2023-10-06T19:12:23Z",
        "closed_at": "2023-10-06T19:34:30Z",
        "merged_at": "2023-10-06T19:34:30Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-06T18:56:29Z",
        "closed_at": "2023-10-06T19:12:44Z",
        "merged_at": "2023-10-06T19:12:44Z",
        "body": "fyi @ofermend ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-06T17:24:42Z",
        "closed_at": "2023-10-06T19:01:48Z",
        "merged_at": "2023-10-06T19:01:48Z",
        "body": "Description: Fixed the Open in Colab link for ClearML docs\r\nIssue: https://github.com/allegroai/clearml/issues/1125\r\nTwitter handle: DziezycMaciej",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-06T17:15:21Z",
        "closed_at": "2023-10-06T17:17:20Z",
        "merged_at": null,
        "body": "Description: Fixed the Open in Colab link for ClearML docs\r\nIssue: https://github.com/allegroai/clearml/issues/1125\r\nTwitter handle: DziezycMaciej",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 203,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2023-10-06T17:14:18Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Description \r\n* Add `_generate` and `_agenerate` to support Fireworks batching.\r\n\r\nIssue - Not applicable\r\nDependencies - None\r\nTag maintainer - @baskaryan  ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-06T17:11:25Z",
        "closed_at": "2023-10-12T01:43:40Z",
        "merged_at": "2023-10-12T01:43:40Z",
        "body": "Replace this entire comment with:\r\n  - **Description:** added a better error description for this error\r\n  - **Issue:** #11407 \r\n  \r\n  @baskaryan ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 190,
        "deletions": 213,
        "changed_files": 15,
        "created_at": "2023-10-06T16:48:56Z",
        "closed_at": "2023-10-09T10:22:03Z",
        "merged_at": "2023-10-09T10:22:03Z",
        "body": "- keep alias for RunnableMap\r\n- update docs to use RunnableParallel and RunnablePassthrough.assign\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-06T16:04:22Z",
        "closed_at": "2023-10-06T16:49:11Z",
        "merged_at": "2023-10-06T16:49:11Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 599,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2023-10-06T15:41:19Z",
        "closed_at": "2023-10-12T02:09:38Z",
        "merged_at": "2023-10-12T02:09:38Z",
        "body": "- **Description**: Adding vectorstore wrapper for [SemaDB](https://rapidapi.com/semafind-semadb/api/semadb).\r\n- **Issue**: None\r\n- **Dependencies**: None\r\n- **Twitter handle**: semafind\r\n\r\nChecks performed:\r\n- [x] `make format`\r\n- [x] `make lint`\r\n- [x] `make test`\r\n- [x] `make spell_check`\r\n- [x] `make docs_build`\r\n\r\nDocumentation added:\r\n\r\n- SemaDB vectorstore wrapper tutorial\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 359,
        "deletions": 18,
        "changed_files": 4,
        "created_at": "2023-10-06T14:48:51Z",
        "closed_at": "2023-10-17T18:51:05Z",
        "merged_at": "2023-10-17T18:51:05Z",
        "body": "Add Cohere retrieval augmented generation to retrievers",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-06T14:44:14Z",
        "closed_at": "2023-10-06T14:44:20Z",
        "merged_at": "2023-10-06T14:44:20Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 286,
        "deletions": 1,
        "changed_files": 6,
        "created_at": "2023-10-06T14:23:46Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-06T12:16:54Z",
        "closed_at": "2023-10-07T05:14:33Z",
        "merged_at": null,
        "body": "This commit addresses the issue where JSON strings with trailing commas would cause parsing to fail. We have added a preprocessing step to correct these commas before attempting to parse the JSON string using the `json.loads()` function.\r\n\r\nChanges:\r\n- Added a `correct_trailing_commas` function that removes trailing commas from a given JSON string.\r\n- Used this function to preprocess the JSON string inside the `parse` method of `PydanticOutputParser`.\r\n\r\nReason:\r\nSome JSON producing systems or manual entries might inadvertently add trailing commas, which are not valid in standard JSON. This change aims to make our parser more robust and forgiving of such common mistakes, thereby reducing potential disruptions or failures due to invalid JSON formats.\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2023-10-06T11:23:07Z",
        "closed_at": "2023-10-06T11:23:29Z",
        "merged_at": null,
        "body": "Enhance the ImportError handling in the code to provide a more informative error message, guiding users on how to install the missing 'betabageldb' package using 'pip'. This change improves user experience and aids in debugging.\r\n@eyurtsev ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 29,
        "changed_files": 1,
        "created_at": "2023-10-06T10:44:29Z",
        "closed_at": "2023-10-12T00:09:02Z",
        "merged_at": "2023-10-12T00:09:02Z",
        "body": "Handle different field names in dicts/dataframes, fixing the ClearML callback.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2023-10-06T09:43:55Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:**\r\nReplace deprecated `InferenceAPI` of Hugging Face Inference with `InferenceClient` in the module `embeddings.huggingface_hub`.\r\n\r\n**Issue:**\r\n#10483 \r\n\r\n**Remarks:**\r\n- A similar PR is open for the module `llms.huggingface_hub`: #10514 \r\n- It's my first contribution to an open source project. Then don't hesitate to send me your comments \ud83d\ude03. \r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2023-10-06T05:46:02Z",
        "closed_at": "2023-10-11T03:34:35Z",
        "merged_at": "2023-10-11T03:34:35Z",
        "body": "  - **Description:** This is an update to OctoAI LLM provider that adds support for llama2 endpoints hosted on OctoAI and updates MPT-7b url with the current one.\r\n@baskaryan\r\nThanks!",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 22,
        "deletions": 12,
        "changed_files": 10,
        "created_at": "2023-10-06T02:19:44Z",
        "closed_at": null,
        "merged_at": null,
        "body": "  - **Description:** Quote tool names in prompt templates\r\n  - **Issue:** https://github.com/langchain-ai/langchain/issues/1657 https://github.com/langchain-ai/langchain/issues/1477 https://github.com/langchain-ai/langchain/issues/1358\r\n  - **Tag maintainer:** @hwchase17\r\n\r\nThe original prompt template is ambiguous because it does not tell whether the tool names should be quoted or not. This PR makes it clear that the tool names should be quoted. It fixes #1358 for Nous-Hermes-Llama2-13b according to my tests.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4167,
        "deletions": 4,
        "changed_files": 16,
        "created_at": "2023-10-06T01:18:40Z",
        "closed_at": "2023-10-06T01:39:45Z",
        "merged_at": "2023-10-06T01:39:45Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-06T01:13:28Z",
        "closed_at": "2023-10-11T00:25:23Z",
        "merged_at": "2023-10-11T00:25:23Z",
        "body": "  - **Description:** Use `raise from` statement so that users can find detailed error message\r\n  - **Tag maintainer:** @baskaryan, @eyurtsev, @hwchase17\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 882,
        "deletions": 39,
        "changed_files": 7,
        "created_at": "2023-10-05T23:27:54Z",
        "closed_at": "2023-10-07T00:02:19Z",
        "merged_at": "2023-10-07T00:02:19Z",
        "body": "In case you don't want to make a dataset / easy to see the OAI formatted message equivalents",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 4,
        "changed_files": 5,
        "created_at": "2023-10-05T22:46:12Z",
        "closed_at": "2023-10-06T00:13:14Z",
        "merged_at": "2023-10-06T00:13:14Z",
        "body": "Added missed docstrings to the `callbacks/`",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 758,
        "deletions": 750,
        "changed_files": 408,
        "created_at": "2023-10-05T22:30:57Z",
        "closed_at": null,
        "merged_at": null,
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-05T22:25:10Z",
        "closed_at": "2023-10-06T00:04:14Z",
        "merged_at": "2023-10-06T00:04:14Z",
        "body": "Replace this entire comment with:\r\n  - **Description:** minor update to constructor to allow for specification of \"source\"\r\n  - **Tag maintainer:** @baskaryan\r\n  - **Twitter handle:** @ofermend\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-05T22:15:33Z",
        "closed_at": "2023-10-05T22:34:06Z",
        "merged_at": "2023-10-05T22:34:06Z",
        "body": "- **Description:** This commit corrects a minor typo in the documentation. It changes \"frum\" to \"from\" in the sentence: \"The results from search are passed back to the LLM for synthesis into an answer\" in the file `docs/extras/use_cases/more/agents/agents.ipynb`. This typo fix enhances the clarity and accuracy of the documentation.\r\n- **Tag maintainer:** @baskaryan",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 96,
        "deletions": 85,
        "changed_files": 2,
        "created_at": "2023-10-05T21:44:57Z",
        "closed_at": "2023-10-05T23:40:01Z",
        "merged_at": "2023-10-05T23:40:01Z",
        "body": "Improve UX for cli\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 567,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2023-10-05T20:47:46Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description** \r\nAdding support to replace documents in Azure Cognitive Search. Right now, we can only upload documents but azure [azure-search-documents](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/azure/search/documents/_search_client.py#L623) provides the option to modify the documents. \r\n\r\n\r\n**References**\r\n- https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/search/azure-search-documents/azure/search/documents/_search_client.py#L623\r\n- https://learn.microsoft.com/en-us/rest/api/searchservice/addupdate-or-delete-documents\r\n\r\n\r\n**Issue** \r\nNone\r\n\r\n**Dependencies** \r\nNone\r\n\r\n**Tag maintainer** \r\n@eyurtsev \r\n\r\n**Example**\r\n[azure_search_modify_documents.ipynb](https://github.com/bhanu-pappala/langchain/blob/azure_modify_documents/docs/extras/modules/vectorstore/azure_search_modify_documents.ipynb)\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-05T20:19:21Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description**\r\nThis PR addresses a rare issue in `OpenAIWhisperParser` that causes it to crash when processing an audio file with a duration very close to the class's chunk size threshold of 20 minutes.\r\n\r\n**Issue**\r\n#11449\r\n\r\n**Dependencies**\r\nNone\r\n\r\n**Tag maintainer**\r\n@agola11 @eyurtsev \r\n\r\n**Twitter handle**\r\nleonardodiegues\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 14,
        "changed_files": 5,
        "created_at": "2023-10-05T17:09:14Z",
        "closed_at": "2023-10-05T17:40:00Z",
        "merged_at": "2023-10-05T17:40:00Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2023-10-05T16:57:36Z",
        "closed_at": "2023-10-05T22:33:11Z",
        "merged_at": "2023-10-05T22:33:11Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-05T16:52:12Z",
        "closed_at": "2023-10-05T18:23:27Z",
        "merged_at": "2023-10-05T18:23:27Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-05T16:23:46Z",
        "closed_at": "2023-10-05T16:29:14Z",
        "merged_at": "2023-10-05T16:29:14Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-05T16:09:46Z",
        "closed_at": "2023-10-05T16:37:09Z",
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2023-10-05T14:29:58Z",
        "closed_at": "2023-10-05T14:51:21Z",
        "merged_at": "2023-10-05T14:51:21Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 78,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-05T13:29:42Z",
        "closed_at": "2023-10-12T15:42:04Z",
        "merged_at": "2023-10-12T15:42:04Z",
        "body": "Description: Introducing an ability to load a transcription document of audio file using [Yandex SpeechKit](https://cloud.yandex.com/en-ru/services/speechkit)\r\nIssue: None\r\nDependencies: yandex-speechkit\r\nTag maintainer: @rlancemartin, @eyurtsev",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-05T13:08:31Z",
        "closed_at": "2023-10-05T20:25:20Z",
        "merged_at": "2023-10-05T20:25:20Z",
        "body": "- **Description:**  Fix the `PyMuPDFLoader` to accept `loader_kwargs` from the document loader's `loader_kwargs` option. This provides more flexibility in formatting the output from documents.\n\n- **Issue:**  The `loader_kwargs` is not passed into the `load` method from the document loader, which limits configuration options.\n\n- **Dependencies:**  None",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2023-10-05T12:26:38Z",
        "closed_at": "2023-10-05T12:55:43Z",
        "merged_at": null,
        "body": "- **Description:**  Fix the `PyMuPDFLoader` to accept `loader_kwargs` from the document loader's `loader_kwargs` option. This provides more flexibility in formatting the output documents.\n\n- **Issue:**  The `loader_kwargs` is not passed into the `load` method from the document loader, which limits configuration options.\n\n- **Dependencies:**  None",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-05T12:20:21Z",
        "closed_at": "2023-10-05T16:07:16Z",
        "merged_at": "2023-10-05T16:07:16Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** changed 'configur' to 'configure', \r\n  - **Issue:** None,\r\n  - **Dependencies:** None,\r\n  - **Tag maintainer:** None,\r\n  - **Twitter handle:** None\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 641,
        "deletions": 65,
        "changed_files": 6,
        "created_at": "2023-10-05T11:57:04Z",
        "closed_at": "2023-10-05T13:27:51Z",
        "merged_at": "2023-10-05T13:27:51Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 89,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2023-10-05T11:43:56Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:**\r\nPreviously when setting up a structured tool with multiple parameters e.g. `arg1, arg2`\r\nwe got a schema validation error by pydantic. The reason for this was simple: Although the required parameters for the tool were correctly identified, they were propagated as string e.g. `'{\"arg1\": \"foo\", \"arg2\": \"bar\"}'`\r\n\r\nThis PR fixes this issue by using the `parse_raw` method if the args are of type string\r\n\r\n**Issue:** \r\nDidn't find a related issue.\r\n\r\n**Dependencies:**\r\nNone\r\n\r\n**Tag maintainer:**\r\nNone\r\n\r\n**Twitter handle:**\r\nNone\r\n\r\n/CC @Depaccu\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-05T09:30:21Z",
        "closed_at": "2023-10-05T19:38:30Z",
        "merged_at": "2023-10-05T19:38:29Z",
        "body": "  - **Description:** added an integration test\r\n  - **Issue:** #11407 \r\n\r\n@baskaryan \r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-05T03:54:13Z",
        "closed_at": "2023-10-05T19:37:56Z",
        "merged_at": "2023-10-05T19:37:56Z",
        "body": "I have restructured the code to ensure uniform handling of ImportError. In place of previously used ValueError, I've adopted the standard practice of raising ImportError with explanatory messages. This modification enhances code readability and clarifies that any problems stem from module importation.\r\n\r\n@baskaryan \r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 200,
        "deletions": 185,
        "changed_files": 1,
        "created_at": "2023-10-05T03:09:45Z",
        "closed_at": "2023-10-05T14:57:20Z",
        "merged_at": "2023-10-05T14:57:20Z",
        "body": "I was hoping this would pick up numpy 1.26, which is required to support the new Python 3.12 release, but it didn't. It seems that some transitive dependency requirement on numpy is preventing that, and the highest we can currently go is 1.24.x.\n\nBut to find this out required a 15min `poetry lock`, so I figured we might as well upgrade the dependencies we can and hopefully make the next dependency upgrade a bit smaller.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1099,
        "deletions": 819,
        "changed_files": 7,
        "created_at": "2023-10-05T02:55:09Z",
        "closed_at": "2023-10-12T01:49:16Z",
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2918,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2023-10-05T00:59:28Z",
        "closed_at": null,
        "merged_at": null,
        "body": "This PR adds [Bigframes (BigQuery DataFrames)](https://cloud.google.com/python/docs/reference/bigframes/latest) integration to Langchain. BigQuery DataFrames provides a Pythonic DataFrame and machine learning (ML) API powered by the BigQuery engine. BigFrames supports manipulating data in the DataFrame to build LLM prompts, and sending DataFrame prompts to the LLM model using [text-bison model of the PaLM API](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text)\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 37,
        "changed_files": 5,
        "created_at": "2023-10-04T23:06:05Z",
        "closed_at": "2023-10-05T14:56:03Z",
        "merged_at": "2023-10-05T14:56:03Z",
        "body": "@nfcampos @eyurtsev @baskaryan ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 247,
        "deletions": 157,
        "changed_files": 2,
        "created_at": "2023-10-04T22:04:24Z",
        "closed_at": "2023-10-09T15:04:26Z",
        "merged_at": "2023-10-09T15:04:26Z",
        "body": "- **Description:** Code Refactoring, Documentation Improvements for Google Document AI PDF Parser\r\n  - Adds Online (synchronous) processing option.\r\n  - Adds default field mask to limit payload size.\r\n  - Skips Human review by default.\r\n- **Issue:** Fixes #10589\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1087,
        "deletions": 817,
        "changed_files": 6,
        "created_at": "2023-10-04T21:43:23Z",
        "closed_at": "2023-10-04T22:59:28Z",
        "merged_at": "2023-10-04T22:59:28Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-04T21:38:42Z",
        "closed_at": "2023-10-06T19:25:46Z",
        "merged_at": "2023-10-06T19:25:46Z",
        "body": " **Description:** add `MarkdownListOutputParser` as a new `ListOutputParser`\r\n **Issue:** #11410 ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-04T20:24:31Z",
        "closed_at": "2023-10-05T14:58:57Z",
        "merged_at": "2023-10-05T14:58:57Z",
        "body": "Add docker compose to cli\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 43,
        "deletions": 51,
        "changed_files": 2,
        "created_at": "2023-10-04T20:07:08Z",
        "closed_at": "2023-10-04T20:25:38Z",
        "merged_at": "2023-10-04T20:25:38Z",
        "body": "Consolidating to a single README for now, will be easier to maintain we can differentiate between poetry and pip later. Does not seem critical.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2023-10-04T20:03:02Z",
        "closed_at": "2023-10-05T03:31:51Z",
        "merged_at": "2023-10-05T03:31:51Z",
        "body": "Log a warning instead of raising an error when validating bedrock anthropic prompts. Let server handle actual error behavior.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-04T19:54:39Z",
        "closed_at": "2023-10-04T20:55:03Z",
        "merged_at": "2023-10-04T20:55:03Z",
        "body": "The person class here: https://python.langchain.com/docs/use_cases/extraction#pydantic-1 has attributes `dog_breed` and `dog_name` that use `Optional` from typing, but it hasn't been imported. Fixed the import here\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** Fix python imports in example, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 162,
        "deletions": 257,
        "changed_files": 2,
        "created_at": "2023-10-04T19:50:38Z",
        "closed_at": "2023-10-05T15:07:39Z",
        "merged_at": "2023-10-05T15:07:39Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 164,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2023-10-04T19:37:39Z",
        "closed_at": "2023-10-12T02:08:54Z",
        "merged_at": "2023-10-12T02:08:54Z",
        "body": "  - **Description:** implements a retriever on top of DocAI Warehouse (to interact with existing enterprise documents)\r\n  https://cloud.google.com/document-ai-warehouse?hl=en\r\n  - **Issue:** new functionality\r\n \r\n@baskaryan \r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 524,
        "deletions": 1584,
        "changed_files": 936,
        "created_at": "2023-10-04T19:32:27Z",
        "closed_at": "2023-10-06T17:09:42Z",
        "merged_at": "2023-10-06T17:09:42Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-10-04T19:11:22Z",
        "closed_at": "2023-10-04T19:34:06Z",
        "merged_at": "2023-10-04T19:34:06Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-04T19:10:24Z",
        "closed_at": "2023-10-12T02:09:03Z",
        "merged_at": "2023-10-12T02:09:03Z",
        "body": "**Description:** Avoid huggingfacepipeline to truncate the response if user setup return_full_text as False within huggingface pipeline.\r\n\r\n**Dependencies:** : None\r\n**Tag maintainer:**   Maybe @sam-h-bean ?\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 503,
        "deletions": 61,
        "changed_files": 2,
        "created_at": "2023-10-04T17:57:13Z",
        "closed_at": "2023-10-05T17:14:05Z",
        "merged_at": "2023-10-05T17:14:05Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 245,
        "deletions": 101,
        "changed_files": 2,
        "created_at": "2023-10-04T17:15:01Z",
        "closed_at": "2023-10-04T19:16:37Z",
        "merged_at": "2023-10-04T19:16:37Z",
        "body": "- Make logs a dictionary keyed by run name (and counter for repeats)\r\n- Ensure no output shows up in lc_serializable format\r\n- Fix up repr for RunLog and RunLogPatch\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-04T17:12:44Z",
        "closed_at": "2023-10-04T19:41:20Z",
        "merged_at": "2023-10-04T19:41:20Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n\r\n## Description\r\nCurrently SQLAlchemy >=1.4.0 is a hard requirement. We are unable to run `from langchain.vectorstores import FAISS` with SQLAlchemy <1.4.0 due to top-level imports, even if we aren't even using parts of the library that use SQLAlchemy. See Testing section for repro. Let's make it so that langchain is still compatible with SQLAlchemy <1.4.0, especially if we aren't using parts of langchain that require it.\r\n\r\nThe main conflict is that SQLAlchemy removed `declarative_base` from `sqlalchemy.ext.declarative` in 1.4.0 and moved it to `sqlalchemy.orm`. We can fix this by try-catching the import. This is the same fix as applied in https://github.com/langchain-ai/langchain/pull/883.\r\n\r\n(I see that there seems to be some refactoring going on about isolating dependencies, e.g. https://github.com/langchain-ai/langchain/commit/c87e9fb2ce0ae617e3b2edde52421c80adef54cc, so if this issue will be eventually fixed by isolating imports in langchain.vectorstores that also works).\r\n\r\n## Issue\r\nI can't find a matching issue.\r\n\r\n## Dependencies\r\nNo additional dependencies\r\n\r\n## Maintainer\r\n@hwchase17 since you reviewed https://github.com/langchain-ai/langchain/pull/883\r\n\r\n## Testing\r\nI didn't add a test, but I manually tested this.\r\n\r\n1. Current failure:\r\n```\r\nlangchain==0.0.305\r\nsqlalchemy==1.3.24\r\n```\r\n\r\n``` python\r\npython -i\r\n>>> from langchain.vectorstores import FAISS\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/pay/src/zoolander/vendor3/lib/python3.8/site-packages/langchain/vectorstores/__init__.py\", line 58, in <module>\r\n    from langchain.vectorstores.pgembedding import PGEmbedding\r\n  File \"/pay/src/zoolander/vendor3/lib/python3.8/site-packages/langchain/vectorstores/pgembedding.py\", line 10, in <module>\r\n    from sqlalchemy.orm import Session, declarative_base, relationship\r\nImportError: cannot import name 'declarative_base' from 'sqlalchemy.orm' (/pay/src/zoolander/vendor3/lib/python3.8/site-packages/sqlalchemy/orm/__init__.py)\r\n```\r\n\r\n2. This fix:\r\n```\r\nlangchain==<this PR>\r\nsqlalchemy==1.3.24\r\n```\r\n\r\n``` python\r\npython -i\r\n>>> from langchain.vectorstores import FAISS\r\n<succeeds>\r\n```\r\n\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 381,
        "deletions": 32,
        "changed_files": 4,
        "created_at": "2023-10-04T17:07:38Z",
        "closed_at": "2023-10-05T16:20:48Z",
        "merged_at": "2023-10-05T16:20:48Z",
        "body": "Add cohere /chat integration and an iPython notebook to demonstrate the addition. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 100,
        "deletions": 147,
        "changed_files": 5,
        "created_at": "2023-10-04T16:58:39Z",
        "closed_at": "2023-10-06T20:40:46Z",
        "merged_at": "2023-10-06T20:40:46Z",
        "body": "fixed several notebooks:\r\n- headers\r\n- formats",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 449,
        "deletions": 14,
        "changed_files": 5,
        "created_at": "2023-10-04T16:23:06Z",
        "closed_at": "2023-10-04T17:54:54Z",
        "merged_at": "2023-10-04T17:54:54Z",
        "body": "- default MessagesPlaceholder one to list of messages\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-04T15:55:49Z",
        "closed_at": "2023-10-04T16:10:09Z",
        "merged_at": "2023-10-04T16:10:09Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2023-10-04T15:53:22Z",
        "closed_at": "2023-10-05T02:32:26Z",
        "merged_at": null,
        "body": null,
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-04T15:52:38Z",
        "closed_at": "2023-10-04T15:56:46Z",
        "merged_at": "2023-10-04T15:56:46Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-04T13:58:13Z",
        "closed_at": "2023-10-04T14:03:18Z",
        "merged_at": "2023-10-04T14:03:18Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2023-10-04T10:08:12Z",
        "closed_at": "2023-10-04T14:17:47Z",
        "merged_at": "2023-10-04T14:17:47Z",
        "body": "  - **Description:** Adds support for custom API URL in the GitHubIssuesLoader. This allows it to be used with Github enterprise instances. \r\n  \r\n  \r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** Adds support for custom API URL in the GitHubIssuesLoader. This allows it to be used with Github enterprise instances. \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-04T09:31:48Z",
        "closed_at": "2023-10-04T15:57:47Z",
        "merged_at": "2023-10-04T15:57:47Z",
        "body": "  - **Description:** a little bit better error description\r\n  - **Issue:** #10879\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2023-10-04T07:05:33Z",
        "closed_at": null,
        "merged_at": null,
        "body": "\u2026e maximum tokens of the buffer\r\n\r\n- **Issue:** #3072 \r\n- **Relate to:** #3345 \r\n- **Description:** I've found same issue in my project with langchain and also read the related PR.\r\nHowever, I thought that instead of actually pruning the messages, just getting the small size buffer is more appropriate.\r\nSo, this is what I've done.\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 107,
        "deletions": 37,
        "changed_files": 1,
        "created_at": "2023-10-04T04:08:23Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T23:27:16Z",
        "closed_at": null,
        "merged_at": null,
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2023-10-03T22:38:48Z",
        "closed_at": "2023-10-04T03:18:15Z",
        "merged_at": "2023-10-04T03:18:15Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2023-10-03T22:15:17Z",
        "closed_at": "2023-10-04T00:28:14Z",
        "merged_at": "2023-10-04T00:28:14Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-03T22:07:35Z",
        "closed_at": "2023-10-03T22:34:39Z",
        "merged_at": "2023-10-03T22:34:39Z",
        "body": "Replace this entire comment with:\r\n  - **Description:** updates to documentation and API headers\r\n  - **Tag maintainer:** @baskarya\r\n  - **Twitter handle:** @ofermend\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 60,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-03T21:03:18Z",
        "closed_at": "2023-10-03T22:35:37Z",
        "merged_at": "2023-10-03T22:35:37Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n\r\n- **Description:** Adds Kotlin language to `TextSplitter`",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-03T20:58:57Z",
        "closed_at": "2023-10-03T21:34:31Z",
        "merged_at": "2023-10-03T21:34:31Z",
        "body": "For external libraries that depend on `type_to_cls_dict`, adds a workaround to continue using the old format.\r\n\r\nRecommend people use `get_type_to_cls_dict()` instead and only resolve the imports when they're used.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T20:27:13Z",
        "closed_at": "2023-10-12T15:53:21Z",
        "merged_at": null,
        "body": "Following up on #11359\r\n\r\n  - **Description:** a description of the change, \r\n\r\nprivateGPT/ingest.py crashes when parsing a txt file with unexpected unicode.\r\n\r\n  - **Issue:** the issue # it fixes (if applicable),\r\n\r\nProblem solved:\r\n\r\nTraceback (most recent call last):\r\nFile \"C:\\Program Files\\Python3\\Lib\\site-packages\\langchain\\document_loaders\\text.py\", line 41, in load text = f.read()\r\n^^^^^^^^\r\nFile \"\", line 322, in decode\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xa7 in position 549: invalid start byte\r\n\r\n  - **Dependencies:** any dependencies required for this change,\r\n\r\nnone\r\n\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n\r\nNo idea.\r\n\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\n@DigitalVisor\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T20:14:32Z",
        "closed_at": "2023-10-05T16:20:18Z",
        "merged_at": "2023-10-05T16:20:18Z",
        "body": " **Description:** Previously if the access to Azure Cognitive Search was not done via an API key, the default credential was called which doesn't allow to use an interactive login. I simply added the option to use \"INTERACTIVE\" as a key name, and this will launch a login window upon initialisation of the AzureSearch object.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 370,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-03T18:48:28Z",
        "closed_at": "2023-10-13T19:25:12Z",
        "merged_at": "2023-10-13T19:25:12Z",
        "body": "- Description: Adds the ChatEverlyAI class with llama-2 7b  on [EverlyAI Hosted\r\nEndpoints](https://everlyai.xyz/)\r\n- It inherits from ChatOpenAI and requires openai (probably unnecessary\r\nbut it made for a quick and easy implementation)",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 14,
        "changed_files": 3,
        "created_at": "2023-10-03T18:33:59Z",
        "closed_at": "2023-10-04T04:43:30Z",
        "merged_at": "2023-10-04T04:43:30Z",
        "body": "This switches to parameterized queries for selecting schemas for all databases, except DuckDB for which I wasn't able to figure out how to get parameterized queries to work: https://github.com/Mause/duckdb_engine/issues/796\r\n\r\nFor all the other databases, I followed the parameterized query approach described by their docs.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 85,
        "changed_files": 3,
        "created_at": "2023-10-03T18:25:31Z",
        "closed_at": "2023-10-05T02:36:58Z",
        "merged_at": "2023-10-05T02:36:58Z",
        "body": "Needs #11353 to merge first, and a new `langchain` to be published with those changes.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2023-10-03T18:16:34Z",
        "closed_at": "2023-10-03T19:19:09Z",
        "merged_at": "2023-10-03T19:19:09Z",
        "body": "The previous API of the `_execute()` function had a few rough edges that this PR addresses:\n- The `fetch` argument was type-hinted as being able to take any string, but any string other than `\"all\"` or `\"one\"` would `raise ValueError`. The new type hints explicitly declare that only those values are supported.\n- The return type was type-hinted as `Sequence` but using `fetch = \"one\"` would actually return a single result item. This was incorrectly suppressed using `# type: ignore`. We now always return a list.\n- Using `fetch = \"one\"` would return a single item if data was found, or an empty *list* if no data was found. This was confusing, and we now always return a list to simplify.\n- The return type was `Sequence[Any]` which was a bit difficult to use since it wasn't clear what one could do with the returned rows. I'm making the new type `Dict[str, Any]` that corresponds to the column names and their values in the query.\n\nI've updated the use of this method elsewhere in the file to match the new behavior.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 56,
        "deletions": 52,
        "changed_files": 4,
        "created_at": "2023-10-03T17:54:22Z",
        "closed_at": "2023-10-04T15:32:42Z",
        "merged_at": "2023-10-04T15:32:42Z",
        "body": "\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T16:50:51Z",
        "closed_at": "2023-10-03T19:27:52Z",
        "merged_at": "2023-10-03T19:27:52Z",
        "body": "Fix for a bug surfaced as part of #11339. `mypy` caught this since the types didn't match up.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-03T16:33:10Z",
        "closed_at": "2023-10-03T21:42:42Z",
        "merged_at": null,
        "body": "\r\n **Description:** Add `BedrockChat` to `get_type_to_cls_dict` map\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T15:58:42Z",
        "closed_at": "2023-10-03T16:01:06Z",
        "merged_at": "2023-10-03T16:01:06Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 8,
        "created_at": "2023-10-03T15:18:28Z",
        "closed_at": "2023-10-03T23:23:54Z",
        "merged_at": "2023-10-03T23:23:54Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 736,
        "deletions": 831,
        "changed_files": 1,
        "created_at": "2023-10-03T15:16:07Z",
        "closed_at": "2023-10-03T23:23:36Z",
        "merged_at": "2023-10-03T23:23:36Z",
        "body": null,
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-03T15:08:51Z",
        "closed_at": "2023-10-03T16:00:17Z",
        "merged_at": "2023-10-03T16:00:17Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-10-03T15:04:44Z",
        "closed_at": "2023-10-03T16:00:38Z",
        "merged_at": "2023-10-03T16:00:38Z",
        "body": "therefor -> therefore\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1616,
        "deletions": 1384,
        "changed_files": 9,
        "created_at": "2023-10-03T15:03:53Z",
        "closed_at": "2023-10-17T01:13:31Z",
        "merged_at": "2023-10-17T01:13:31Z",
        "body": "Part of upgrading our CI to use Poetry 1.6.1.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 37,
        "changed_files": 29,
        "created_at": "2023-10-03T14:58:40Z",
        "closed_at": "2023-10-03T19:56:09Z",
        "merged_at": "2023-10-03T19:56:09Z",
        "body": "  - **Description:** use term keyword according to the official python doc glossary, see https://docs.python.org/3/glossary.html\r\n  - **Issue:** not applicable\r\n  - **Dependencies:** not applicable\r\n  - **Tag maintainer:** @hwchase17\r\n  - **Twitter handle:** vreyespue\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-03T14:21:03Z",
        "closed_at": "2023-10-03T14:22:53Z",
        "merged_at": "2023-10-03T14:22:53Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-03T13:53:42Z",
        "closed_at": "2023-10-04T15:12:55Z",
        "merged_at": "2023-10-04T15:12:55Z",
        "body": "  - **Description:** add a paragraph to the GoogleDriveLoader doc on how to bypass errors on authentication.\r\n\r\nFor some reason, specifying credential path via `credentials_path` constructor parameter when creating `GoogleDriveLoader` makes it so that the oAuth screen is never showing up when first using GoogleDriveLoader. Instead, the `RefreshError: ('invalid_grant: Bad Request', {'error': 'invalid_grant', 'error_description': 'Bad Request'})` error happens. Setting it via `os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = ...` solves the problem. Also, `token_path` constructor parameter is mandatory, otherwise another error happens when trying to `load()` for the first time.\r\n\r\nThese errors are tricky and time-consuming to figure out, so I believe it's good to mention them in the docs.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1421,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2023-10-03T13:27:18Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Following this tutoral about using OpenAI Embeddings with FAISS\r\n\r\nhttps://python.langchain.com/docs/integrations/vectorstores/faiss\r\n\r\n```python\r\nfrom langchain.embeddings.openai import OpenAIEmbeddings\r\nfrom langchain.text_splitter import CharacterTextSplitter\r\nfrom langchain.vectorstores import FAISS\r\nfrom langchain.document_loaders import TextLoader\r\nfrom langchain.document_loaders import TextLoader\r\n\r\nloader = TextLoader(\"../../../extras/modules/state_of_the_union.txt\")\r\ndocuments = loader.load()\r\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\r\ndocs = text_splitter.split_documents(documents)\r\n\r\nembeddings = OpenAIEmbeddings()\r\n```\r\n\r\nThis works fine\r\n\r\n```python\r\ndb = FAISS.from_documents(docs, embeddings)\r\nquery = \"What did the president say about Ketanji Brown Jackson\"\r\ndocs = db.similarity_search(query)\r\n```\r\n\r\nBut the async version is not\r\n\r\n```python\r\ndb = await FAISS.afrom_documents(docs, embeddings)  # NotImplementedError\r\nquery = \"What did the president say about Ketanji Brown Jackson\"\r\n\r\ndocs = await db.asimilarity_search(query) # this will use await asyncio.get_event_loop().run_in_executor under the hood and will not call OpenAIEmbeddings.aembed_query but call OpenAIEmbeddings.embed_query\r\n```\r\n\r\nSo this PR add async/await supports for FAISS",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-03T12:31:30Z",
        "closed_at": "2023-10-04T04:04:59Z",
        "merged_at": "2023-10-04T04:04:59Z",
        "body": "\u2026ish with an error\r\n\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1154,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2023-10-03T11:49:15Z",
        "closed_at": "2023-10-04T18:59:11Z",
        "merged_at": "2023-10-04T18:59:11Z",
        "body": "Addition of Vespa vector store integration including notebook showing its use. \r\n\r\nMaintainer: @lesters \r\nTwitter handle: LesterSolbakken\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2023-10-03T10:48:42Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Hey, we're looking to invest more in adding cohere integrations to langchain so would love to get more of an idea for how it's used. Hopefully this pr is acceptable. This week I'm also going to be looking into adding our new [retrieval augmented generation product](https://txt.cohere.com/chat-with-rag/) to langchain. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 107,
        "deletions": 20,
        "changed_files": 4,
        "created_at": "2023-10-03T10:18:11Z",
        "closed_at": "2023-10-09T15:06:44Z",
        "merged_at": "2023-10-09T15:06:44Z",
        "body": "Added autodetect_encoding option to csvLoader like TextLoader.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 55,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T09:23:35Z",
        "closed_at": null,
        "merged_at": null,
        "body": "**Description:** \r\nRevise `libs/langchain/langchain/document_loaders/async_html.py` to store the HTML Title and Page Language in the `metadata` of `AsyncHtmlLoader`.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-03T08:51:22Z",
        "closed_at": "2023-10-03T08:55:03Z",
        "merged_at": "2023-10-03T08:55:03Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T07:19:10Z",
        "closed_at": "2023-10-04T22:03:03Z",
        "merged_at": null,
        "body": null,
        "comments": 4
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 9,
        "changed_files": 8,
        "created_at": "2023-10-03T06:25:09Z",
        "closed_at": "2023-10-04T01:46:26Z",
        "merged_at": "2023-10-04T01:46:26Z",
        "body": "I've refactored the code to ensure that ImportError is consistently handled. Instead of using ValueError as before, I've now followed the standard practice of raising ImportError along with clear and informative error messages. This change enhances the code's clarity and explicitly signifies that any problems are associated with module imports.\r\n\r\nCC: @baskaryan , @hwchase17 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 617,
        "deletions": 59,
        "changed_files": 12,
        "created_at": "2023-10-03T05:16:16Z",
        "closed_at": null,
        "merged_at": null,
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-03T04:10:00Z",
        "closed_at": "2023-10-03T05:16:00Z",
        "merged_at": "2023-10-03T05:16:00Z",
        "body": "@baskaryan , Small typo fix",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2023-10-03T04:06:07Z",
        "closed_at": "2023-10-03T04:15:56Z",
        "merged_at": null,
        "body": "@baskaryan, Fixed a small typo errors",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-03T01:18:02Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Change warning class to LangChain Deprecation Warning instead of generic User Warning\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 134,
        "deletions": 80,
        "changed_files": 1,
        "created_at": "2023-10-03T00:06:54Z",
        "closed_at": "2023-10-03T15:17:47Z",
        "merged_at": "2023-10-03T15:17:47Z",
        "body": "Add Mistral example with prompt support",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 163,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-10-02T23:21:30Z",
        "closed_at": "2023-10-03T00:12:17Z",
        "merged_at": "2023-10-03T00:12:17Z",
        "body": "@baskaryan @efriis",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 82,
        "deletions": 87,
        "changed_files": 5,
        "created_at": "2023-10-02T21:34:40Z",
        "closed_at": "2023-10-04T20:44:23Z",
        "merged_at": "2023-10-04T20:44:23Z",
        "body": "There are several pages in `integrations/providers/more` that belongs to Google  and AWS `integrations/providers`.\r\n- moved content of these pages into the Google  and AWS `integrations/providers` pages \r\n- removed these individual pages",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 479,
        "deletions": 119,
        "changed_files": 22,
        "created_at": "2023-10-02T21:15:54Z",
        "closed_at": "2023-10-12T22:48:04Z",
        "merged_at": "2023-10-12T22:48:04Z",
        "body": "Instead of accessing `langchain.debug`, `langchain.verbose`, or `langchain.llm_cache`, please use the new getter/setter functions in `langchain.globals`:\r\n- `langchain.globals.set_debug()` and `langchain.globals.get_debug()`\r\n- `langchain.globals.set_verbose()` and `langchain.globals.get_verbose()`\r\n- `langchain.globals.set_llm_cache()` and `langchain.globals.get_llm_cache()`\r\n\r\nUsing the old globals directly will now raise a warning.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-02T20:58:02Z",
        "closed_at": "2023-10-08T12:54:05Z",
        "merged_at": null,
        "body": "**Description:**\r\n \r\nMock action in a FakeListLLM uses a wrong name for the REPL tool (the correct one uses '_').\r\nWithout it, an error pops up: \"Python REPL is not a valid tool, try one of [Python_REPL].\"",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-02T20:29:18Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Description: \r\nThis PR adds the ability for users to provide a custom retry decorator when creating an instance of the ChatOpenAI class. The custom decorator will be used in the acompletion_with_retry and completion_with_retry methods to handle retries for the API calls. If a custom decorator is not provided, the default retry decorator will be used. This feature provides users the flexibility to handle specific use cases and errors in specific ways.\r\n\r\nIssue: https://github.com/langchain-ai/langchain/issues/3109\r\n\r\nDependencies: No new dependencies are required for this change.",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-10-02T20:18:38Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Fixes #11261 ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1996,
        "deletions": 2046,
        "changed_files": 5,
        "created_at": "2023-10-02T19:57:51Z",
        "closed_at": "2023-10-02T22:06:42Z",
        "merged_at": "2023-10-02T22:06:42Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 585,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2023-10-02T19:35:28Z",
        "closed_at": "2023-10-02T20:00:14Z",
        "merged_at": "2023-10-02T20:00:14Z",
        "body": "Add LLMBashChain to experimental\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 150,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2023-10-02T19:10:53Z",
        "closed_at": "2023-10-05T20:48:11Z",
        "merged_at": "2023-10-05T20:48:11Z",
        "body": "Replace this entire comment with:\r\n  - **Description:** Add you.com retriever to langchain, \r\n  - **Issue:** N/A,\r\n  - **Dependencies:** N/A,\r\n  - **Tag maintainer:** @hwchase17 ,\r\n  - **Twitter handle:** TBD!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 33,
        "changed_files": 2,
        "created_at": "2023-10-02T18:55:39Z",
        "closed_at": "2023-10-02T19:06:32Z",
        "merged_at": "2023-10-02T19:06:32Z",
        "body": "After this PR, numexpr is an optional dependency. In addition,  the min version constraint of 2.8.6 means that there is input sanitization.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 12,
        "changed_files": 3,
        "created_at": "2023-10-02T18:28:10Z",
        "closed_at": "2023-10-04T15:32:24Z",
        "merged_at": "2023-10-04T15:32:24Z",
        "body": "Bedrock anthropic api enforces that Human and Assistant messages must be interleaved (cannot have same type twice in a row). We current treat System Messages as human messages when converting messages -> string prompt. Our validation when using Bedrock/BedrockChat raises an error when this happens. For ChatAnthropic we don't validate this so no error is raised, but perhaps the behavior is still suboptimal.\r\n\r\nWould love input from folks more familiar with Anthropic intended usage and Bedrock API.",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-02T18:11:20Z",
        "closed_at": "2023-10-05T16:48:22Z",
        "merged_at": "2023-10-05T16:48:22Z",
        "body": "In preparation for migration LLMBashChain and related tools add a derprecation warning to the code.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 1,
        "changed_files": 6,
        "created_at": "2023-10-02T17:30:15Z",
        "closed_at": null,
        "merged_at": null,
        "body": "Python 3.12 came out a few hours ago, so in this PR:\r\n- We make linting use 3.12 instead of 3.11, since that's the max version we support. (We also lint on 3.8, the min version we support.)\r\n- We add 3.12 to the test matrices for all other CI runs.\r\n\r\nFixes #11479.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-10-02T16:55:30Z",
        "closed_at": "2023-10-04T01:47:08Z",
        "merged_at": "2023-10-04T01:47:08Z",
        "body": "**Description:** \r\n\r\nExamples in the \"Select by similarity\" section were not really highlighting capabilities of similarity search.\r\nE.g. \"# Input is a measurement, so should select the tall/short example\" was still outputting the \"mood\" example.\r\n\r\nI tweaked the inputs a bit and fixed the examples (checking that those are indeed what the search outputs).",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-02T16:42:00Z",
        "closed_at": "2023-10-04T15:35:55Z",
        "merged_at": "2023-10-04T15:35:55Z",
        "body": "This reverts commit ff90bb59bf78a85bf561e03385e40ca855745ddb.\r\n\r\nRequires #11296 to merge first.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-02T16:40:58Z",
        "closed_at": "2023-10-02T17:53:03Z",
        "merged_at": "2023-10-02T17:53:03Z",
        "body": "Should resolve the issue here: https://github.com/langchain-ai/langchain/actions/runs/6342767671/job/17229204508#step:7:36\n\nAfter this merges, we can revert https://github.com/langchain-ai/langchain/pull/11192\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-10-02T16:27:25Z",
        "closed_at": "2023-10-02T19:36:58Z",
        "merged_at": "2023-10-02T19:36:58Z",
        "body": "**Description:**\r\n\r\nFix a forgotten closing bracket in the length-based selector snippet",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-10-02T14:51:52Z",
        "closed_at": "2023-10-02T15:27:12Z",
        "merged_at": "2023-10-02T15:27:12Z",
        "body": "<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-02T14:35:18Z",
        "closed_at": "2023-10-04T00:36:17Z",
        "merged_at": "2023-10-04T00:36:17Z",
        "body": "  - **Description:** Fix typo about `RetrievalQAWithSourceChain`  ->  `RetrievalQAWithSourcesChain`\r\n<!-- Thank you for contributing to LangChain!\r\n\r\nReplace this entire comment with:\r\n  - **Description:** a description of the change, \r\n  - **Issue:** the issue # it fixes (if applicable),\r\n  - **Dependencies:** any dependencies required for this change,\r\n  - **Tag maintainer:** for a quicker response, tag the relevant maintainer (see below),\r\n  - **Twitter handle:** we announce bigger features on Twitter. If your PR gets announced, and you'd like a mention, we'll gladly shout you out!\r\n\r\nPlease make sure your PR is passing linting and testing before submitting. Run `make format`, `make lint` and `make test` to check this locally.\r\n\r\nSee contribution guidelines for more information on how to write/run tests, lint, etc: \r\nhttps://github.com/langchain-ai/langchain/blob/master/.github/CONTRIBUTING.md\r\n\r\nIf you're adding a new integration, please include:\r\n  1. a test for the integration, preferably unit tests that do not rely on network access,\r\n  2. an example notebook showing its use. It lives in `docs/extras` directory.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of @baskaryan, @eyurtsev, @hwchase17.\r\n -->\r\n",
        "comments": 1
    }
]